{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fastbook"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KA4OS0BbCWW",
        "outputId": "abbb6d22-a683-404b-9d5d-f0803ca15948"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fastbook in /usr/local/lib/python3.7/dist-packages (0.0.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastbook) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastbook) (1.3.5)\n",
            "Requirement already satisfied: fastai>=2.6 in /usr/local/lib/python3.7/dist-packages (from fastbook) (2.7.7)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from fastbook) (0.10.1)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastbook) (21.1.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (from fastbook) (2.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastbook) (2.23.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from fastbook) (4.21.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from fastbook) (0.1.97)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.6->fastbook) (0.13.0+cu113)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai>=2.6->fastbook) (3.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai>=2.6->fastbook) (6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai>=2.6->fastbook) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai>=2.6->fastbook) (1.0.2)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.4.5 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.6->fastbook) (1.5.13)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.6->fastbook) (1.0.3)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.6->fastbook) (0.0.7)\n",
            "Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.6->fastbook) (7.1.2)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.6->fastbook) (3.4.1)\n",
            "Requirement already satisfied: torch<1.13,>=1.7 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.6->fastbook) (1.12.0+cu113)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.6->fastbook) (2.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.6->fastbook) (2.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.6->fastbook) (4.64.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.6->fastbook) (0.6.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.6->fastbook) (2.11.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.6->fastbook) (0.4.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.6->fastbook) (1.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.6->fastbook) (1.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.6->fastbook) (3.0.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.6->fastbook) (2.4.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.6->fastbook) (57.4.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.6->fastbook) (8.1.0)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.6->fastbook) (4.1.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.6->fastbook) (3.0.9)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.6->fastbook) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.6->fastbook) (1.21.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.6->fastbook) (3.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.6->fastbook) (1.9.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<4->fastai>=2.6->fastbook) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastbook) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<4->fastai>=2.6->fastbook) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastbook) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastbook) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastbook) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastbook) (2.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai>=2.6->fastbook) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<4->fastai>=2.6->fastbook) (7.1.2)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets->fastbook) (0.18.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets->fastbook) (3.8.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->fastbook) (0.70.13)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets->fastbook) (2022.7.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets->fastbook) (3.0.0)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets->fastbook) (0.3.5.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets->fastbook) (0.8.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets->fastbook) (4.12.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->fastbook) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets->fastbook) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->fastbook) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->fastbook) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->fastbook) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->fastbook) (2.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->fastbook) (1.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->fastbook) (1.8.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->fastbook) (22.1.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->fastbook) (0.13.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<4->fastai>=2.6->fastbook) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai>=2.6->fastbook) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai>=2.6->fastbook) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai>=2.6->fastbook) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fastai>=2.6->fastbook) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastbook) (2022.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai>=2.6->fastbook) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai>=2.6->fastbook) (1.1.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers->fastbook) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->fastbook) (2022.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "eN6vXLGna05F"
      },
      "outputs": [],
      "source": [
        "import fastbook\n",
        "fastbook.setup_book()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.all import *"
      ],
      "metadata": {
        "id": "NKosGxWfboz2"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mporting  necessary libraries\n",
        "import random"
      ],
      "metadata": {
        "id": "96ysHOVsXDWG"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#untaring(getting the path to a specific dataset)--- downloads directly from the net and untars it into a folder\n",
        "#S3  = 'https://s3.amazonaws.com/fast-ai-', URL = f'{S3}sample/',  MNIST_SAMPLE = f'{URL}mnist_sample.tgz'\n",
        "#so URLs.MNIST_SAMPLE= 'https://s3.amazonaws.com/fast-ai-sample/mnist_sample.tgz'\n",
        "path = untar_data(URLs.MNIST_SAMPLE)"
      ],
      "metadata": {
        "id": "k1h6pEEAgIV8"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this means the files have been downloaded in the current directry under different subdirectories\n",
        "path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LCz9pVzsdWO",
        "outputId": "c0aed42a-f751-4d2f-8d98-83023094e75a"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('.')"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DOnt know what this does\n",
        "#this renders Path('/root/.fastai/data/mnist_sample') as the current directory '.' or base path\n",
        "#and make  the representation easier\n",
        "Path.BASE_PATH= path"
      ],
      "metadata": {
        "id": "8dJ-p_rfnBkG"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#subdirectories contained in the actual path\n",
        "path.ls()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UgtKDaKo1wO",
        "outputId": "4b1503a9-09c0-4ea2-bfad-82a8ba1acd4d"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [Path('train'),Path('labels.csv'),Path('valid')]"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now we can have a look at each directory\n",
        "(path/'labels.csv').is_file()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAhgYlIfsqkT",
        "outputId": "26032649-6170-4c5f-e6dd-b2b207ce6b1a"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(path/'train').ls()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qH9eU1_s3oq",
        "outputId": "6b55bac3-df51-40b9-efd1-ed43cc99e401"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('train/7'),Path('train/3')]"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(path/'valid').ls()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XTgjAaqs54l",
        "outputId": "e343dcdd-2d44-4ba2-f6b6-0a7feef8831a"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('valid/7'),Path('valid/3')]"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we can see tha the train directory has 2 sub_folders one for 3s and one for 7s\n",
        "# now we are going to put all the content of the 3s into one list and do the same for 7s\n",
        "threes = (path/'train'/'3').ls().sorted()\n",
        "sevens =  (path/'train'/'7').ls().sorted()"
      ],
      "metadata": {
        "id": "2wcldyOrtFYn"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFSuVIujt3M6",
        "outputId": "cab13add-540b-49a4-c05a-68dd00793464"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#6131) [Path('train/3/10.png'),Path('train/3/10000.png'),Path('train/3/10011.png'),Path('train/3/10031.png'),Path('train/3/10034.png'),Path('train/3/10042.png'),Path('train/3/10052.png'),Path('train/3/1007.png'),Path('train/3/10074.png'),Path('train/3/10091.png')...]"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sevens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NzUhZJzt7Aa",
        "outputId": "cc27f975-fb5a-4f3c-9dbc-687d442541f1"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#6265) [Path('train/7/10002.png'),Path('train/7/1001.png'),Path('train/7/10014.png'),Path('train/7/10019.png'),Path('train/7/10039.png'),Path('train/7/10046.png'),Path('train/7/10050.png'),Path('train/7/10063.png'),Path('train/7/10077.png'),Path('train/7/10086.png')...]"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "so there are are 6131 training images for 3s and 6265 training images for 7s"
      ],
      "metadata": {
        "id": "OT06hp_At8hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#le'S Check how they look\n",
        "im_10_png = Image.open(threes[1])\n",
        "im_10_png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "FmKI8EkVuHcs",
        "outputId": "c375353a-754c-481d-af7d-4f208c97773c"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FAAA6D80910>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9ElEQVR4nM3Or0sDcRjH8c/pgrfBVBjCgibThiKIyTWbWF1bORhGwxARxH/AbtW0JoIGwzXRYhJhtuFY2q1ocLgbe3sGReTuuWbwkx6+r+/zQ/pncX6q+YOldSe6nG3dn8U/rTQ70L8FCGJUewvxl7NTmezNb8xIkvKugr1HSeMP6SrWOVkoTEuSyh0Gm2n3hQyObMnXnxkempRrvgD+gokzwxFAr7U7YXHZ8x4A/Dl7rbu6D2yl3etcw/F3nZgfRVI7rXM7hMUUqzzBec427x26rkmlkzEEa4nnRqnSOH2F0UUx0ePzlbuqMXAHgN6GY9if5xP8dmtHFfwjuQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "im_1000_png = Image.open(threes[1])\n",
        "im_1000_png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "NsHa0PGUvUka",
        "outputId": "f89c7981-4649-4d14-aa15-d1c9d3c31584"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FAAAA92C790>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9ElEQVR4nM3Or0sDcRjH8c/pgrfBVBjCgibThiKIyTWbWF1bORhGwxARxH/AbtW0JoIGwzXRYhJhtuFY2q1ocLgbe3sGReTuuWbwkx6+r+/zQ/pncX6q+YOldSe6nG3dn8U/rTQ70L8FCGJUewvxl7NTmezNb8xIkvKugr1HSeMP6SrWOVkoTEuSyh0Gm2n3hQyObMnXnxkempRrvgD+gokzwxFAr7U7YXHZ8x4A/Dl7rbu6D2yl3etcw/F3nZgfRVI7rXM7hMUUqzzBec427x26rkmlkzEEa4nnRqnSOH2F0UUx0ePzlbuqMXAHgN6GY9if5xP8dmtHFfwjuQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "im_1011_png = Image.open(threes[1])\n",
        "im_1011_png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "ikV5BL8OvT43",
        "outputId": "b975752e-fbea-48a7-c86b-c1caafaa37e2"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FAAAA8DB650>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9ElEQVR4nM3Or0sDcRjH8c/pgrfBVBjCgibThiKIyTWbWF1bORhGwxARxH/AbtW0JoIGwzXRYhJhtuFY2q1ocLgbe3sGReTuuWbwkx6+r+/zQ/pncX6q+YOldSe6nG3dn8U/rTQ70L8FCGJUewvxl7NTmezNb8xIkvKugr1HSeMP6SrWOVkoTEuSyh0Gm2n3hQyObMnXnxkempRrvgD+gokzwxFAr7U7YXHZ8x4A/Dl7rbu6D2yl3etcw/F3nZgfRVI7rXM7hMUUqzzBec427x26rkmlkzEEa4nnRqnSOH2F0UUx0ePzlbuqMXAHgN6GY9if5xP8dmtHFfwjuQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#because everything is reperesented in computers in terms of numbers and that deep learning algorithms also works well with numbers rather than object as they are, we \n",
        "#are now going to transform this images in appropriate forms (numpy arrays- tensors)\n",
        "\n",
        "im_1011_as_np_array = array(im_1011_png)\n",
        "im_1011_as_np_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIDGv-l6vnvP",
        "outputId": "b52a4f4a-bd18-4e1a-d481-7fbd3a64412d"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "im_1011_as_np_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XrMD88mScl5",
        "outputId": "b80a7c6e-42bb-495d-c373-6241b23f4fc9"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  29, 150, 195, 254, 255, 254, 176, 193, 150,  96,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  48, 166, 224, 253, 253, 234, 196, 253, 253, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,  93, 244, 249, 253, 187,  46,  10,   8,   4,  10, 194, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0, 107, 253, 253, 230,  48,   0,   0,   0,   0,   0, 192, 253, 253, 156,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   3,  20,  20,  15,   0,   0,   0,   0,   0,  43, 224, 253, 245,  74,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249, 253, 245, 126,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  14, 101, 223, 253, 248, 124,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 166, 239, 253, 253, 253, 187,  30,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  16, 248, 250, 253, 253, 253, 253, 232, 213, 111,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43,  98,  98, 208, 253, 253, 253, 253, 187,  22,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   9,  51, 119, 253, 253, 253,  76,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 183, 253, 253, 139,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 182, 253, 253, 104,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  85, 249, 253, 253,  36,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  60, 214, 253, 253, 173,  11,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  98, 247, 253, 253, 226,   9,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  42, 150, 252, 253, 253, 233,  53,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  42, 115,  42,  60, 115, 159, 240, 253, 253, 250, 175,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0, 187, 253, 253, 253, 253, 253, 253, 253, 197,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0, 103, 253, 253, 253, 253, 253, 232,  67,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see that when  we transform the image into an array we get a 28x28 array of pixel values ranging from 0-255\n",
        "we can also have this into a Pytorch tensor by applying the tensor function directly "
      ],
      "metadata": {
        "id": "863SsVJLQZD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the tensor function is a  wrapper for as_tensor of pytorch but can take multiple arrays at once\n",
        "im_1011_as_pytorch_tensor = tensor(im_1011_png)\n",
        "im_1011_as_pytorch_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JR5WCqMwsjp",
        "outputId": "29c6c97d-5360-4aed-f2ef-c89920e685cc"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "im_1011_as_pytorch_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bHHTpW0SVUu",
        "outputId": "484650e5-bfc1-4846-8483-71d43bef8b71"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  29, 150, 195, 254, 255, 254, 176, 193, 150,  96,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,  48, 166, 224, 253, 253, 234, 196, 253, 253, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,  93, 244, 249, 253, 187,  46,  10,   8,   4,  10, 194, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0, 107, 253, 253, 230,  48,   0,   0,   0,   0,   0, 192, 253, 253, 156,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   3,  20,  20,  15,   0,   0,   0,   0,   0,  43, 224, 253, 245,  74,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249, 253, 245, 126,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  14, 101, 223, 253, 248, 124,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 166, 239, 253, 253, 253, 187,  30,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  16, 248, 250, 253, 253, 253, 253, 232, 213, 111,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43,  98,  98, 208, 253, 253, 253, 253, 187,  22,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   9,  51, 119, 253, 253, 253,  76,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 183, 253, 253, 139,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 182, 253, 253, 104,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  85, 249, 253, 253,  36,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  60, 214, 253, 253, 173,  11,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  98, 247, 253, 253, 226,   9,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  42, 150, 252, 253, 253, 233,  53,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,  42, 115,  42,  60, 115, 159, 240, 253, 253, 250, 175,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0, 187, 253, 253, 253, 253, 253, 253, 253, 197,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0, 103, 253, 253, 253, 253, 253, 232,  67,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for visualising this pixelated frame we can transform the tensor or ndarray in a dataframe and\n",
        "#color the background according to the value of the content of each cell\n",
        "\n",
        "#we select just a a part of the image\n",
        "df = pd.DataFrame(im_1011_as_pytorch_tensor[4:15,4:22])\n",
        "df.style.set_properties(**{'font-size':'6pt'}).background_gradient(\"Greys\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "0qaZdPsNeJyw",
        "outputId": "473816fe-33c6-437c-b34d-aabc402347b1"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7faaa6d7fa10>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_252b4_row0_col0, #T_252b4_row0_col1, #T_252b4_row0_col2, #T_252b4_row0_col3, #T_252b4_row0_col4, #T_252b4_row0_col5, #T_252b4_row0_col6, #T_252b4_row0_col7, #T_252b4_row0_col8, #T_252b4_row0_col9, #T_252b4_row0_col10, #T_252b4_row0_col11, #T_252b4_row0_col12, #T_252b4_row0_col13, #T_252b4_row0_col14, #T_252b4_row0_col15, #T_252b4_row0_col16, #T_252b4_row0_col17, #T_252b4_row1_col0, #T_252b4_row1_col1, #T_252b4_row1_col2, #T_252b4_row1_col3, #T_252b4_row1_col4, #T_252b4_row1_col15, #T_252b4_row1_col16, #T_252b4_row1_col17, #T_252b4_row2_col0, #T_252b4_row2_col1, #T_252b4_row2_col2, #T_252b4_row2_col15, #T_252b4_row2_col16, #T_252b4_row2_col17, #T_252b4_row3_col0, #T_252b4_row3_col15, #T_252b4_row3_col16, #T_252b4_row3_col17, #T_252b4_row4_col0, #T_252b4_row4_col6, #T_252b4_row4_col7, #T_252b4_row4_col8, #T_252b4_row4_col9, #T_252b4_row4_col10, #T_252b4_row4_col15, #T_252b4_row4_col16, #T_252b4_row4_col17, #T_252b4_row5_col0, #T_252b4_row5_col5, #T_252b4_row5_col6, #T_252b4_row5_col7, #T_252b4_row5_col8, #T_252b4_row5_col9, #T_252b4_row5_col15, #T_252b4_row5_col16, #T_252b4_row5_col17, #T_252b4_row6_col0, #T_252b4_row6_col1, #T_252b4_row6_col2, #T_252b4_row6_col3, #T_252b4_row6_col4, #T_252b4_row6_col5, #T_252b4_row6_col6, #T_252b4_row6_col7, #T_252b4_row6_col8, #T_252b4_row6_col9, #T_252b4_row6_col14, #T_252b4_row6_col15, #T_252b4_row6_col16, #T_252b4_row6_col17, #T_252b4_row7_col0, #T_252b4_row7_col1, #T_252b4_row7_col2, #T_252b4_row7_col3, #T_252b4_row7_col4, #T_252b4_row7_col5, #T_252b4_row7_col6, #T_252b4_row7_col13, #T_252b4_row7_col14, #T_252b4_row7_col15, #T_252b4_row7_col16, #T_252b4_row7_col17, #T_252b4_row8_col0, #T_252b4_row8_col1, #T_252b4_row8_col2, #T_252b4_row8_col3, #T_252b4_row8_col4, #T_252b4_row8_col13, #T_252b4_row8_col14, #T_252b4_row8_col15, #T_252b4_row8_col16, #T_252b4_row8_col17, #T_252b4_row9_col0, #T_252b4_row9_col1, #T_252b4_row9_col2, #T_252b4_row9_col3, #T_252b4_row9_col4, #T_252b4_row9_col16, #T_252b4_row9_col17, #T_252b4_row10_col0, #T_252b4_row10_col1, #T_252b4_row10_col2, #T_252b4_row10_col3, #T_252b4_row10_col4, #T_252b4_row10_col5, #T_252b4_row10_col6, #T_252b4_row10_col17 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #ffffff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_252b4_row1_col5 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #efefef;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_252b4_row1_col6, #T_252b4_row1_col13 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #7c7c7c;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row1_col7 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #4a4a4a;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row1_col8, #T_252b4_row1_col9, #T_252b4_row1_col10, #T_252b4_row2_col5, #T_252b4_row2_col6, #T_252b4_row2_col7, #T_252b4_row2_col11, #T_252b4_row2_col12, #T_252b4_row2_col13, #T_252b4_row3_col4, #T_252b4_row3_col12, #T_252b4_row3_col13, #T_252b4_row4_col1, #T_252b4_row4_col2, #T_252b4_row4_col3, #T_252b4_row4_col12, #T_252b4_row4_col13, #T_252b4_row5_col12, #T_252b4_row6_col11, #T_252b4_row9_col11, #T_252b4_row10_col11, #T_252b4_row10_col12, #T_252b4_row10_col13, #T_252b4_row10_col14, #T_252b4_row10_col15, #T_252b4_row10_col16 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #000000;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row1_col11 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #606060;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row1_col12 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #4d4d4d;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row1_col14 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #bbbbbb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_252b4_row2_col3 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #e4e4e4;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_252b4_row2_col4, #T_252b4_row8_col6 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #6b6b6b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row2_col8, #T_252b4_row2_col14, #T_252b4_row3_col14 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #171717;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row2_col9, #T_252b4_row3_col11 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #4b4b4b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row2_col10, #T_252b4_row7_col10, #T_252b4_row8_col8, #T_252b4_row8_col10, #T_252b4_row9_col8, #T_252b4_row9_col10 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #010101;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row3_col1 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #272727;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row3_col2 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #0a0a0a;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row3_col3 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #050505;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row3_col5 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #333333;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row3_col6 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #e6e6e6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_252b4_row3_col7, #T_252b4_row3_col10 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #fafafa;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_252b4_row3_col8 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #fbfbfb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_252b4_row3_col9 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #fdfdfd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_252b4_row4_col4 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #1b1b1b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row4_col5 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #e0e0e0;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_252b4_row4_col11 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #4e4e4e;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row4_col14 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #767676;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row5_col1 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #fcfcfc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_252b4_row5_col2, #T_252b4_row5_col3 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #f6f6f6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_252b4_row5_col4, #T_252b4_row7_col7 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #f8f8f8;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_252b4_row5_col10, #T_252b4_row10_col7 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #e8e8e8;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_252b4_row5_col11 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #222222;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row5_col13, #T_252b4_row6_col12 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #090909;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row5_col14 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #d0d0d0;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_252b4_row6_col10, #T_252b4_row7_col11, #T_252b4_row9_col6 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #060606;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row6_col13 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #979797;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row7_col8 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #b6b6b6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_252b4_row7_col9 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #252525;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row7_col12 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #999999;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row8_col5 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #f9f9f9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_252b4_row8_col7 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #101010;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row8_col9, #T_252b4_row9_col9 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #020202;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row8_col11 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #545454;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row8_col12 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #f1f1f1;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_252b4_row9_col5 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #f7f7f7;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_252b4_row9_col7 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #030303;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row9_col12 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #181818;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row9_col13 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #303030;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row9_col14 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #a9a9a9;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_252b4_row9_col15 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #fefefe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_252b4_row10_col8, #T_252b4_row10_col9 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #bababa;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_252b4_row10_col10 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #393939;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_252b4_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >0</th>\n",
              "      <th class=\"col_heading level0 col1\" >1</th>\n",
              "      <th class=\"col_heading level0 col2\" >2</th>\n",
              "      <th class=\"col_heading level0 col3\" >3</th>\n",
              "      <th class=\"col_heading level0 col4\" >4</th>\n",
              "      <th class=\"col_heading level0 col5\" >5</th>\n",
              "      <th class=\"col_heading level0 col6\" >6</th>\n",
              "      <th class=\"col_heading level0 col7\" >7</th>\n",
              "      <th class=\"col_heading level0 col8\" >8</th>\n",
              "      <th class=\"col_heading level0 col9\" >9</th>\n",
              "      <th class=\"col_heading level0 col10\" >10</th>\n",
              "      <th class=\"col_heading level0 col11\" >11</th>\n",
              "      <th class=\"col_heading level0 col12\" >12</th>\n",
              "      <th class=\"col_heading level0 col13\" >13</th>\n",
              "      <th class=\"col_heading level0 col14\" >14</th>\n",
              "      <th class=\"col_heading level0 col15\" >15</th>\n",
              "      <th class=\"col_heading level0 col16\" >16</th>\n",
              "      <th class=\"col_heading level0 col17\" >17</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_252b4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_252b4_row0_col0\" class=\"data row0 col0\" >0</td>\n",
              "      <td id=\"T_252b4_row0_col1\" class=\"data row0 col1\" >0</td>\n",
              "      <td id=\"T_252b4_row0_col2\" class=\"data row0 col2\" >0</td>\n",
              "      <td id=\"T_252b4_row0_col3\" class=\"data row0 col3\" >0</td>\n",
              "      <td id=\"T_252b4_row0_col4\" class=\"data row0 col4\" >0</td>\n",
              "      <td id=\"T_252b4_row0_col5\" class=\"data row0 col5\" >0</td>\n",
              "      <td id=\"T_252b4_row0_col6\" class=\"data row0 col6\" >0</td>\n",
              "      <td id=\"T_252b4_row0_col7\" class=\"data row0 col7\" >0</td>\n",
              "      <td id=\"T_252b4_row0_col8\" class=\"data row0 col8\" >0</td>\n",
              "      <td id=\"T_252b4_row0_col9\" class=\"data row0 col9\" >0</td>\n",
              "      <td id=\"T_252b4_row0_col10\" class=\"data row0 col10\" >0</td>\n",
              "      <td id=\"T_252b4_row0_col11\" class=\"data row0 col11\" >0</td>\n",
              "      <td id=\"T_252b4_row0_col12\" class=\"data row0 col12\" >0</td>\n",
              "      <td id=\"T_252b4_row0_col13\" class=\"data row0 col13\" >0</td>\n",
              "      <td id=\"T_252b4_row0_col14\" class=\"data row0 col14\" >0</td>\n",
              "      <td id=\"T_252b4_row0_col15\" class=\"data row0 col15\" >0</td>\n",
              "      <td id=\"T_252b4_row0_col16\" class=\"data row0 col16\" >0</td>\n",
              "      <td id=\"T_252b4_row0_col17\" class=\"data row0 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_252b4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_252b4_row1_col0\" class=\"data row1 col0\" >0</td>\n",
              "      <td id=\"T_252b4_row1_col1\" class=\"data row1 col1\" >0</td>\n",
              "      <td id=\"T_252b4_row1_col2\" class=\"data row1 col2\" >0</td>\n",
              "      <td id=\"T_252b4_row1_col3\" class=\"data row1 col3\" >0</td>\n",
              "      <td id=\"T_252b4_row1_col4\" class=\"data row1 col4\" >0</td>\n",
              "      <td id=\"T_252b4_row1_col5\" class=\"data row1 col5\" >29</td>\n",
              "      <td id=\"T_252b4_row1_col6\" class=\"data row1 col6\" >150</td>\n",
              "      <td id=\"T_252b4_row1_col7\" class=\"data row1 col7\" >195</td>\n",
              "      <td id=\"T_252b4_row1_col8\" class=\"data row1 col8\" >254</td>\n",
              "      <td id=\"T_252b4_row1_col9\" class=\"data row1 col9\" >255</td>\n",
              "      <td id=\"T_252b4_row1_col10\" class=\"data row1 col10\" >254</td>\n",
              "      <td id=\"T_252b4_row1_col11\" class=\"data row1 col11\" >176</td>\n",
              "      <td id=\"T_252b4_row1_col12\" class=\"data row1 col12\" >193</td>\n",
              "      <td id=\"T_252b4_row1_col13\" class=\"data row1 col13\" >150</td>\n",
              "      <td id=\"T_252b4_row1_col14\" class=\"data row1 col14\" >96</td>\n",
              "      <td id=\"T_252b4_row1_col15\" class=\"data row1 col15\" >0</td>\n",
              "      <td id=\"T_252b4_row1_col16\" class=\"data row1 col16\" >0</td>\n",
              "      <td id=\"T_252b4_row1_col17\" class=\"data row1 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_252b4_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_252b4_row2_col0\" class=\"data row2 col0\" >0</td>\n",
              "      <td id=\"T_252b4_row2_col1\" class=\"data row2 col1\" >0</td>\n",
              "      <td id=\"T_252b4_row2_col2\" class=\"data row2 col2\" >0</td>\n",
              "      <td id=\"T_252b4_row2_col3\" class=\"data row2 col3\" >48</td>\n",
              "      <td id=\"T_252b4_row2_col4\" class=\"data row2 col4\" >166</td>\n",
              "      <td id=\"T_252b4_row2_col5\" class=\"data row2 col5\" >224</td>\n",
              "      <td id=\"T_252b4_row2_col6\" class=\"data row2 col6\" >253</td>\n",
              "      <td id=\"T_252b4_row2_col7\" class=\"data row2 col7\" >253</td>\n",
              "      <td id=\"T_252b4_row2_col8\" class=\"data row2 col8\" >234</td>\n",
              "      <td id=\"T_252b4_row2_col9\" class=\"data row2 col9\" >196</td>\n",
              "      <td id=\"T_252b4_row2_col10\" class=\"data row2 col10\" >253</td>\n",
              "      <td id=\"T_252b4_row2_col11\" class=\"data row2 col11\" >253</td>\n",
              "      <td id=\"T_252b4_row2_col12\" class=\"data row2 col12\" >253</td>\n",
              "      <td id=\"T_252b4_row2_col13\" class=\"data row2 col13\" >253</td>\n",
              "      <td id=\"T_252b4_row2_col14\" class=\"data row2 col14\" >233</td>\n",
              "      <td id=\"T_252b4_row2_col15\" class=\"data row2 col15\" >0</td>\n",
              "      <td id=\"T_252b4_row2_col16\" class=\"data row2 col16\" >0</td>\n",
              "      <td id=\"T_252b4_row2_col17\" class=\"data row2 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_252b4_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_252b4_row3_col0\" class=\"data row3 col0\" >0</td>\n",
              "      <td id=\"T_252b4_row3_col1\" class=\"data row3 col1\" >93</td>\n",
              "      <td id=\"T_252b4_row3_col2\" class=\"data row3 col2\" >244</td>\n",
              "      <td id=\"T_252b4_row3_col3\" class=\"data row3 col3\" >249</td>\n",
              "      <td id=\"T_252b4_row3_col4\" class=\"data row3 col4\" >253</td>\n",
              "      <td id=\"T_252b4_row3_col5\" class=\"data row3 col5\" >187</td>\n",
              "      <td id=\"T_252b4_row3_col6\" class=\"data row3 col6\" >46</td>\n",
              "      <td id=\"T_252b4_row3_col7\" class=\"data row3 col7\" >10</td>\n",
              "      <td id=\"T_252b4_row3_col8\" class=\"data row3 col8\" >8</td>\n",
              "      <td id=\"T_252b4_row3_col9\" class=\"data row3 col9\" >4</td>\n",
              "      <td id=\"T_252b4_row3_col10\" class=\"data row3 col10\" >10</td>\n",
              "      <td id=\"T_252b4_row3_col11\" class=\"data row3 col11\" >194</td>\n",
              "      <td id=\"T_252b4_row3_col12\" class=\"data row3 col12\" >253</td>\n",
              "      <td id=\"T_252b4_row3_col13\" class=\"data row3 col13\" >253</td>\n",
              "      <td id=\"T_252b4_row3_col14\" class=\"data row3 col14\" >233</td>\n",
              "      <td id=\"T_252b4_row3_col15\" class=\"data row3 col15\" >0</td>\n",
              "      <td id=\"T_252b4_row3_col16\" class=\"data row3 col16\" >0</td>\n",
              "      <td id=\"T_252b4_row3_col17\" class=\"data row3 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_252b4_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_252b4_row4_col0\" class=\"data row4 col0\" >0</td>\n",
              "      <td id=\"T_252b4_row4_col1\" class=\"data row4 col1\" >107</td>\n",
              "      <td id=\"T_252b4_row4_col2\" class=\"data row4 col2\" >253</td>\n",
              "      <td id=\"T_252b4_row4_col3\" class=\"data row4 col3\" >253</td>\n",
              "      <td id=\"T_252b4_row4_col4\" class=\"data row4 col4\" >230</td>\n",
              "      <td id=\"T_252b4_row4_col5\" class=\"data row4 col5\" >48</td>\n",
              "      <td id=\"T_252b4_row4_col6\" class=\"data row4 col6\" >0</td>\n",
              "      <td id=\"T_252b4_row4_col7\" class=\"data row4 col7\" >0</td>\n",
              "      <td id=\"T_252b4_row4_col8\" class=\"data row4 col8\" >0</td>\n",
              "      <td id=\"T_252b4_row4_col9\" class=\"data row4 col9\" >0</td>\n",
              "      <td id=\"T_252b4_row4_col10\" class=\"data row4 col10\" >0</td>\n",
              "      <td id=\"T_252b4_row4_col11\" class=\"data row4 col11\" >192</td>\n",
              "      <td id=\"T_252b4_row4_col12\" class=\"data row4 col12\" >253</td>\n",
              "      <td id=\"T_252b4_row4_col13\" class=\"data row4 col13\" >253</td>\n",
              "      <td id=\"T_252b4_row4_col14\" class=\"data row4 col14\" >156</td>\n",
              "      <td id=\"T_252b4_row4_col15\" class=\"data row4 col15\" >0</td>\n",
              "      <td id=\"T_252b4_row4_col16\" class=\"data row4 col16\" >0</td>\n",
              "      <td id=\"T_252b4_row4_col17\" class=\"data row4 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_252b4_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_252b4_row5_col0\" class=\"data row5 col0\" >0</td>\n",
              "      <td id=\"T_252b4_row5_col1\" class=\"data row5 col1\" >3</td>\n",
              "      <td id=\"T_252b4_row5_col2\" class=\"data row5 col2\" >20</td>\n",
              "      <td id=\"T_252b4_row5_col3\" class=\"data row5 col3\" >20</td>\n",
              "      <td id=\"T_252b4_row5_col4\" class=\"data row5 col4\" >15</td>\n",
              "      <td id=\"T_252b4_row5_col5\" class=\"data row5 col5\" >0</td>\n",
              "      <td id=\"T_252b4_row5_col6\" class=\"data row5 col6\" >0</td>\n",
              "      <td id=\"T_252b4_row5_col7\" class=\"data row5 col7\" >0</td>\n",
              "      <td id=\"T_252b4_row5_col8\" class=\"data row5 col8\" >0</td>\n",
              "      <td id=\"T_252b4_row5_col9\" class=\"data row5 col9\" >0</td>\n",
              "      <td id=\"T_252b4_row5_col10\" class=\"data row5 col10\" >43</td>\n",
              "      <td id=\"T_252b4_row5_col11\" class=\"data row5 col11\" >224</td>\n",
              "      <td id=\"T_252b4_row5_col12\" class=\"data row5 col12\" >253</td>\n",
              "      <td id=\"T_252b4_row5_col13\" class=\"data row5 col13\" >245</td>\n",
              "      <td id=\"T_252b4_row5_col14\" class=\"data row5 col14\" >74</td>\n",
              "      <td id=\"T_252b4_row5_col15\" class=\"data row5 col15\" >0</td>\n",
              "      <td id=\"T_252b4_row5_col16\" class=\"data row5 col16\" >0</td>\n",
              "      <td id=\"T_252b4_row5_col17\" class=\"data row5 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_252b4_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_252b4_row6_col0\" class=\"data row6 col0\" >0</td>\n",
              "      <td id=\"T_252b4_row6_col1\" class=\"data row6 col1\" >0</td>\n",
              "      <td id=\"T_252b4_row6_col2\" class=\"data row6 col2\" >0</td>\n",
              "      <td id=\"T_252b4_row6_col3\" class=\"data row6 col3\" >0</td>\n",
              "      <td id=\"T_252b4_row6_col4\" class=\"data row6 col4\" >0</td>\n",
              "      <td id=\"T_252b4_row6_col5\" class=\"data row6 col5\" >0</td>\n",
              "      <td id=\"T_252b4_row6_col6\" class=\"data row6 col6\" >0</td>\n",
              "      <td id=\"T_252b4_row6_col7\" class=\"data row6 col7\" >0</td>\n",
              "      <td id=\"T_252b4_row6_col8\" class=\"data row6 col8\" >0</td>\n",
              "      <td id=\"T_252b4_row6_col9\" class=\"data row6 col9\" >0</td>\n",
              "      <td id=\"T_252b4_row6_col10\" class=\"data row6 col10\" >249</td>\n",
              "      <td id=\"T_252b4_row6_col11\" class=\"data row6 col11\" >253</td>\n",
              "      <td id=\"T_252b4_row6_col12\" class=\"data row6 col12\" >245</td>\n",
              "      <td id=\"T_252b4_row6_col13\" class=\"data row6 col13\" >126</td>\n",
              "      <td id=\"T_252b4_row6_col14\" class=\"data row6 col14\" >0</td>\n",
              "      <td id=\"T_252b4_row6_col15\" class=\"data row6 col15\" >0</td>\n",
              "      <td id=\"T_252b4_row6_col16\" class=\"data row6 col16\" >0</td>\n",
              "      <td id=\"T_252b4_row6_col17\" class=\"data row6 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_252b4_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_252b4_row7_col0\" class=\"data row7 col0\" >0</td>\n",
              "      <td id=\"T_252b4_row7_col1\" class=\"data row7 col1\" >0</td>\n",
              "      <td id=\"T_252b4_row7_col2\" class=\"data row7 col2\" >0</td>\n",
              "      <td id=\"T_252b4_row7_col3\" class=\"data row7 col3\" >0</td>\n",
              "      <td id=\"T_252b4_row7_col4\" class=\"data row7 col4\" >0</td>\n",
              "      <td id=\"T_252b4_row7_col5\" class=\"data row7 col5\" >0</td>\n",
              "      <td id=\"T_252b4_row7_col6\" class=\"data row7 col6\" >0</td>\n",
              "      <td id=\"T_252b4_row7_col7\" class=\"data row7 col7\" >14</td>\n",
              "      <td id=\"T_252b4_row7_col8\" class=\"data row7 col8\" >101</td>\n",
              "      <td id=\"T_252b4_row7_col9\" class=\"data row7 col9\" >223</td>\n",
              "      <td id=\"T_252b4_row7_col10\" class=\"data row7 col10\" >253</td>\n",
              "      <td id=\"T_252b4_row7_col11\" class=\"data row7 col11\" >248</td>\n",
              "      <td id=\"T_252b4_row7_col12\" class=\"data row7 col12\" >124</td>\n",
              "      <td id=\"T_252b4_row7_col13\" class=\"data row7 col13\" >0</td>\n",
              "      <td id=\"T_252b4_row7_col14\" class=\"data row7 col14\" >0</td>\n",
              "      <td id=\"T_252b4_row7_col15\" class=\"data row7 col15\" >0</td>\n",
              "      <td id=\"T_252b4_row7_col16\" class=\"data row7 col16\" >0</td>\n",
              "      <td id=\"T_252b4_row7_col17\" class=\"data row7 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_252b4_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_252b4_row8_col0\" class=\"data row8 col0\" >0</td>\n",
              "      <td id=\"T_252b4_row8_col1\" class=\"data row8 col1\" >0</td>\n",
              "      <td id=\"T_252b4_row8_col2\" class=\"data row8 col2\" >0</td>\n",
              "      <td id=\"T_252b4_row8_col3\" class=\"data row8 col3\" >0</td>\n",
              "      <td id=\"T_252b4_row8_col4\" class=\"data row8 col4\" >0</td>\n",
              "      <td id=\"T_252b4_row8_col5\" class=\"data row8 col5\" >11</td>\n",
              "      <td id=\"T_252b4_row8_col6\" class=\"data row8 col6\" >166</td>\n",
              "      <td id=\"T_252b4_row8_col7\" class=\"data row8 col7\" >239</td>\n",
              "      <td id=\"T_252b4_row8_col8\" class=\"data row8 col8\" >253</td>\n",
              "      <td id=\"T_252b4_row8_col9\" class=\"data row8 col9\" >253</td>\n",
              "      <td id=\"T_252b4_row8_col10\" class=\"data row8 col10\" >253</td>\n",
              "      <td id=\"T_252b4_row8_col11\" class=\"data row8 col11\" >187</td>\n",
              "      <td id=\"T_252b4_row8_col12\" class=\"data row8 col12\" >30</td>\n",
              "      <td id=\"T_252b4_row8_col13\" class=\"data row8 col13\" >0</td>\n",
              "      <td id=\"T_252b4_row8_col14\" class=\"data row8 col14\" >0</td>\n",
              "      <td id=\"T_252b4_row8_col15\" class=\"data row8 col15\" >0</td>\n",
              "      <td id=\"T_252b4_row8_col16\" class=\"data row8 col16\" >0</td>\n",
              "      <td id=\"T_252b4_row8_col17\" class=\"data row8 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_252b4_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_252b4_row9_col0\" class=\"data row9 col0\" >0</td>\n",
              "      <td id=\"T_252b4_row9_col1\" class=\"data row9 col1\" >0</td>\n",
              "      <td id=\"T_252b4_row9_col2\" class=\"data row9 col2\" >0</td>\n",
              "      <td id=\"T_252b4_row9_col3\" class=\"data row9 col3\" >0</td>\n",
              "      <td id=\"T_252b4_row9_col4\" class=\"data row9 col4\" >0</td>\n",
              "      <td id=\"T_252b4_row9_col5\" class=\"data row9 col5\" >16</td>\n",
              "      <td id=\"T_252b4_row9_col6\" class=\"data row9 col6\" >248</td>\n",
              "      <td id=\"T_252b4_row9_col7\" class=\"data row9 col7\" >250</td>\n",
              "      <td id=\"T_252b4_row9_col8\" class=\"data row9 col8\" >253</td>\n",
              "      <td id=\"T_252b4_row9_col9\" class=\"data row9 col9\" >253</td>\n",
              "      <td id=\"T_252b4_row9_col10\" class=\"data row9 col10\" >253</td>\n",
              "      <td id=\"T_252b4_row9_col11\" class=\"data row9 col11\" >253</td>\n",
              "      <td id=\"T_252b4_row9_col12\" class=\"data row9 col12\" >232</td>\n",
              "      <td id=\"T_252b4_row9_col13\" class=\"data row9 col13\" >213</td>\n",
              "      <td id=\"T_252b4_row9_col14\" class=\"data row9 col14\" >111</td>\n",
              "      <td id=\"T_252b4_row9_col15\" class=\"data row9 col15\" >2</td>\n",
              "      <td id=\"T_252b4_row9_col16\" class=\"data row9 col16\" >0</td>\n",
              "      <td id=\"T_252b4_row9_col17\" class=\"data row9 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_252b4_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_252b4_row10_col0\" class=\"data row10 col0\" >0</td>\n",
              "      <td id=\"T_252b4_row10_col1\" class=\"data row10 col1\" >0</td>\n",
              "      <td id=\"T_252b4_row10_col2\" class=\"data row10 col2\" >0</td>\n",
              "      <td id=\"T_252b4_row10_col3\" class=\"data row10 col3\" >0</td>\n",
              "      <td id=\"T_252b4_row10_col4\" class=\"data row10 col4\" >0</td>\n",
              "      <td id=\"T_252b4_row10_col5\" class=\"data row10 col5\" >0</td>\n",
              "      <td id=\"T_252b4_row10_col6\" class=\"data row10 col6\" >0</td>\n",
              "      <td id=\"T_252b4_row10_col7\" class=\"data row10 col7\" >43</td>\n",
              "      <td id=\"T_252b4_row10_col8\" class=\"data row10 col8\" >98</td>\n",
              "      <td id=\"T_252b4_row10_col9\" class=\"data row10 col9\" >98</td>\n",
              "      <td id=\"T_252b4_row10_col10\" class=\"data row10 col10\" >208</td>\n",
              "      <td id=\"T_252b4_row10_col11\" class=\"data row10 col11\" >253</td>\n",
              "      <td id=\"T_252b4_row10_col12\" class=\"data row10 col12\" >253</td>\n",
              "      <td id=\"T_252b4_row10_col13\" class=\"data row10 col13\" >253</td>\n",
              "      <td id=\"T_252b4_row10_col14\" class=\"data row10 col14\" >253</td>\n",
              "      <td id=\"T_252b4_row10_col15\" class=\"data row10 col15\" >187</td>\n",
              "      <td id=\"T_252b4_row10_col16\" class=\"data row10 col16\" >22</td>\n",
              "      <td id=\"T_252b4_row10_col17\" class=\"data row10 col17\" >0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see that we selected the \n",
        "pixel of the top half othe 3 "
      ],
      "metadata": {
        "id": "JBDHJiHRfqSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BASELINE ALGORITHM**: We check for the average of the pixel values for each ouf our groups  and then we can compate the pixel average of any new image with our baseline and classify accordingly.For every pixel position, we want to compute the average over all the images of the intensity of that pixel.For that it would be great if we had a data structure that could group all the images into one single data structure that can be manipulated at once, that is where tensors get in handy, they are the main data structure in pytorch and deep learning programming, think of them as a way to represent data/images in such a way that applying deep learning will be easy, or as the big brother of nd.array"
      ],
      "metadata": {
        "id": "_5llQXimgAJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for that we first group all the tensors in one list- one for each cathegory so a list of \n",
        "#all the 7 tensors and a list of all the 3 tensors\n",
        "\n",
        "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
        "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
        "\n",
        "(len(three_tensors),len(seven_tensors))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGhTX6ESfxg4",
        "outputId": "61102080-288e-456b-ecc7-1b65f49229a9"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6131, 6265)"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch core are basic pytorch functions used in fastai, show_image is one such function which displays a \n",
        "#a pytorch tensor containing an image\n",
        "show_image(three_tensors[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "bj4Zi6MPg9FO",
        "outputId": "946005ed-a5bc-4dd1-a447-1591517e9823"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7faaa6d4a790>"
            ]
          },
          "metadata": {},
          "execution_count": 148
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#because want to calculate the average value of a pixel overall (considering all the images of a specific category) we will first of all \n",
        "#To do this we first combine all the images in this list into a single three-dimensional tensor.The most common way to describe such a tensor is to call it a rank-3 tensor. \n",
        "#We often need to stack up individual tensors in a collection into a single tensor. Pytorch has an inbuilt function to do just this. because some arithmetic\n",
        "#operations in pytorch can only be performed on floats , we cast everything into float, pixels values are expected to be between 0 and 1 when floats so we devide everything by 255\n",
        "#t\n",
        "\n",
        "\n",
        "stacked_threes = torch.stack(three_tensors).float()/255\n",
        "stacked_sevens = torch.stack(seven_tensors).float()/255\n"
      ],
      "metadata": {
        "id": "axLrGUyCi7La"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the shape of this single tensor now\n",
        "stacked_threes.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWgjn2uUqeSC",
        "outputId": "7c049b51-4c8f-444e-a07c-c7c86257f519"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6131, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see it's now a  rank-3 tensor with 6131 in depth and 28 x28 in surface think of it as a cube.Perhaps the most important attribute of a tensor is its shape. This tells you the length of each axis. In this case, we can see that we have 6,131 images, each of size 2828 pixels. There is nothing specifically about this tensor that says that the first axis is the number of images, the second is the height, and the third is the widththe semantics of a tensor are entirely up to us, and how we construct it. As far as PyTorch is concerned, it is just a bunch of numbers in memory. the length of a tensor's shape is its rank"
      ],
      "metadata": {
        "id": "aaDyUanqq7u7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the advantage of the rank-n tensor is that although it is one single bundle we can still access individual tensors\n",
        "stacked_threes[0]\n",
        "stacked_threes[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh2-aFFAY5TF",
        "outputId": "fe887b7a-51ba-494e-c8c8-148e5ee31b9d"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now we calculate the mean of all the pixels\n",
        "\n",
        "mean_threes = stacked_threes.mean(0)\n",
        "mean_sevens = stacked_sevens.mean(0)"
      ],
      "metadata": {
        "id": "Wl0IIq03svNM"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#don't forget that show_image is a pytorch function that can show images stored as tensors\n",
        "show_image(mean_threes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "m8NFxs2P2Rw3",
        "outputId": "5f649e0f-0c55-405e-84de-e0427f45d5d2"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7faaa6a83f90>"
            ]
          },
          "metadata": {},
          "execution_count": 153
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOnUlEQVR4nO2c224kyXGGv4jMrKo+8TizI2vHliBZgA8QfGM/gh/BT+lH8Av4zrAvDBgWLBvGrjQ7szMcsrvrkIfwRVY3udRYwpCzs4bBAIrVJMHsyj8jI+L/I5tiZjzZrekP/QD/1+wJkHv2BMg9ewLknj0Bcs/87/vl3+rf/b9NQf9Q/l4+9PMnD7lnT4DcsydA7tkTIPfs9wbV783kg/HsD9tnoBnfPyCHyYvON6mvVZDD7/QDjloKAEeuVQysYGX+3sp8/7QgfVpA7kz+MHFxCs4hzoFz4P3xZ3hX/+Zwwe0ES4FcICVsvpMzlvN8L7cAWflkwHwaQOQweVdXvmnqpNsWCQFbtFjbUNYNpXWkhacEIXWCOSGHA5Ag2ZACbjLcZPh9RseM20V0Suh+gCliw4BNEaapAvSJgHkcIPOqHlZfvEeCr0A0DbbsKF0gr1vSwhFPPHEhxJWQWyEvoHgoTR3OBCRLBWQAN0G4cfjBaK8Dri+E64D2Edk6ZJwwESwliAnLUL/8EIDc8QppAhI8slhA11I2C9KqZTpviGtHfynEjTBeGGlT0POB5XLki/WO06bnst0TNKMYfQ70OfCq33DVd3z7dg3XgfZ1oLmBxetAsy10rxe43YRebaEfYLuDJFjkUZ7yKA8R5xCn1StCA4sO6xrypiOuPeOZY1oL47kQT4x4kfDryLPzGy4Xe75cXnEZdjwLW4JkWo3sS0M0x3+3F7xZrPmVGlftgtEWlEaRpBQn6BQIAmFsETMYxwpCzo9ykocBIlLBCL5uk9kz8umKvG4YnjeMJ8r+hRA3xvRFJGwmfvrsihfLG362fMMXzTV/HN5y5nZc6p5WMp2U41u8XrVc5SX/fPon/Lp/zj+dfsm3V2u23YLmSine0y0VMXDOoVMEwGICsQdvnQcCokdgDpnDvMNaRwlKDkLxYArmgDlmxuzYxpZv44qMEs2x0Q2v3Z5OI0sZaSQTJLErLYMFHMZCJ5YhctMm9p2RF0ZuhdQKpVG0nTPYHNT57B4CNYgGD03A2oC1Dbnz5IWSOiE3gvkaKCmQouNqv6CPnuuxI7hM0IzXQqOJziVWfuIs7Dn1PUudaDUylECriU0YGZae/aYlWiBeOzQLaenQKeCaADHWAJ8zZvKgOPIgQETvFVvFwKymzAwuGmUCN0jNAt5RJmU3Ona+cBXKXHoYogVVI4RMFxIn3cB5u+e86TkLe6I5ignJDl5ZL9P5EsEEbC70HluNPNhD5H75bYakghszYS9IVrAaa8NWMQfFuw+OZQqxNYYW3pxkdB05Oem5WO1ZhYnORcbs5/c1iloFRWQG6ANU4HNnGTNDrMBcORITOqU6aFA0GlKUEgTfQ3FzPLk/jgNzQloKkqE0SmkdMTtyUYrVyRYTclGsSK1VMmgyJNWFkFxqmV/K777JR9iDALFiiBiWC0KCcUKKoaqoT2jMmFfCewUnFKfzit4ZRAVTOVas44miJ7VgKwsl51swVOwIikXFTYIbma9SFyLlWuab3fKdzwXIjEoNXgApVc8dFcsONcNUUa+YE9TpEQBTqSD5Wk/kRkidklbCtIG0KbiTidNVz0W3p/ORRhO5KGP0MCluENxg+MFwY0aHdOQ6PAKMxwECWM5IKUdQSOm2hBcBp3V/q2K+kjkLjtJ6bBlAIbfCtBHGcxgvM/7ZwI8urnm5vuLLxRVj8YzFE4syjAG/dfit0NwUmuuM247IfsCmqXIbK7dM+LMBYgUrWreNguSMlVLLjVwqI3WuBlbvK713SmkDZRmIa8904hhPlfG8lvTxMrG83PPy7D0/P3nDRdhx4Xf8Zjpll1r2Y0McPE0vhB2EveH7jAwRpjhzmfyo7fJwQA6gZBCT+hAq1WX1QPcV876CFDzmHGUZmE4D/aVnuBCG58b0LLF8vuNn51f82ekrft695ifNawpKNuVtWhFN2Q8NbAPhBppro7lO+PezdwzVQ8j50Yz3gR5ix1RnpdYSFK3eUkqtGEUR72/J3knH8Lyhv1D6L4TxsmAvRl5c3PDnF6/4xfIb/mLxFc/dNWc6clMarkuHk8JUPCUrEgVNoNHQVJCcZ90kPzqYPg6QAyjMqlbR3wVFBWYtJJ11DJcN2z9yDM9heDlx8mzHX734il9uvuJvFr/mJ/6al36BIkDLV3kPNYszZUdONbvoBC6CTAWJGTsISEcl7XGgfDKR+bA6MhM/vMe6hrJsmDaB8USPgXPzbMdPzt/xl+vf8Iv2FT/2N2xUUIREpreJXVEGCwA0LuNDJneF3EHqhNI5rPFICDWIu4NK90C9drbHCUSHrWPllvAdYkgIlLYhrwLTiTKe1W3iLkf+9OINvzz9mr9e/gd/7K956QKteJwoY0nsLbO3wGABxfBSaNpEXBRy50gLSJ3DtR6d+RTjOD/DDyUQ/T47rJRXiqv1xoGKlCzcxI6vhzP+1b/kt37Lf7prnBQcxmAbBgtc5SW70rLNLUEz625kWnumU48UoX3v0Nyi+wVqVjMNzME+/zAC0dGO3nFHMHa1KDuQMAQwsKxsp4ZXw4Z/0x+xcBNrNx6HiuaOhA6gzw1eCqftQN4ob05bxBzjqaDJEa6bGlz7odZBoj+AHnIE4na/Hhkw1NVJGRkzbsg0u0IJSuqUODX8drrgVXfKvy+eo1pw7raQclJpwaKJNC4fyZ2IsWom3m0i0aiekpTmuqmkct/OnKoWZ5+V/n8HjLstB/kuKBITbsz4XaGZy3Q3CnEMlOBJvq38RuzIdcwb5o2rZcZ3kbNNz3nX47SwbkYWy5F9gbh26CSkpeL6gDYBSS3WD7V98cBY8mAJ8S4Qx6aT6m3TKWdkiuhOabziRo8fHalV0qJupeI50nhTmUt5yA3EE0daed4WJRfhbDGwChONT8S2Bla3gLhQ3NLh2waJqYpWOWNZH7RtPh6QGYz6egbDzbzeuQpMmZlwrKTPi+B6h+sD5pXSaPUMldlDZNZLhDQrbsMkTJNjbAP70LJqIgToQiJlx9TWjJNbIXeKBVf50kFKJM4Z8OO2zcMVM5nV9rlMPwBy257Q21iyH8Apvp9qsFWtFdAcgE0EC4p5JW4CbuXIbdVSpkmJ0TFlRyr1fZwWcHV7FV+BtKAQPKgDrd77kLj6YJFZ3Fyaq1QCNwMid9uSUEvraSZ+h8bWndfozIaDrxM6PNhaSUuQKFiWo1hUHcowtaOIbU4wP2/XR0qJHweIfNczaNvqCSFUqq9aY8GdPq0Uu9UpbL7KnUa1cyClTmKWC0yF3NR4Yo3hfcG7jIphMGcQOMz6uO1EkA889vcHCBzL4+ohtyU6IscVtoMnlDKraoCUqmrNQBy6+jJLBYe9bjKvuKtB17yhrqBiR+XM5hpF/pAbfO9pV/S2qT0zWQuesuqwoJTGgZszhoFY1Tx1ypAqGZOcKzCz95hT8I6yasmLwPC8YThT+ufC+KwQTkfON3s2zXhUzmJ26KRolDp+stux5xMCD2W+Hx9DVI6R3ILHmkBZeCwoqXNVJnQHD6mtCTdpffAxIdkhY0ZmL6nZQcmrQFx5prUynQhxbZR14mQ5ctoOdC6hYlVszopkkESVA/Jha5bbbflAe1hQVUG8r4C0jrT0lFaZ1o4SILW1pqhSALNCDm40NBsa5+1SqoSYQ5UR43pWz84y/lnPj8+2vFjecN707HLDkAK7oWHYNrRbnZWzgt9mdD8h40SZ4sxlHiYjfhQgtw2qOV26GghLo+S54CoB4nKOAWEuQufVdBNoEiTdjlmaCkpcQ9wY8TwTzgZ+dH7Dy/UVmzCwdiN9DiRT4uRhdLgRdGQWmgvEVAleKY8Smj8KECuGOI5ddsl2DGzFUWn5QphOIbdGXhdMDZzN0ZIaW7LM3TeDpqBtpltOXC4HXiy3vFhccxZ6Tl3P+7xgl1pe9Rteb1ekbzuad0r3xuiujPbthLsZkO0e6/tZMPrcbPduCj288ewxJUDujLwosIm4UGia6hKqNv+JoGo4LSyayKqZuOx2PGt3PG9ueOa3BKkxY5tbxuK5GVv2+xa3VcJOCLtC2GV0H5F+wmKsnf9HbJeHAZKrbIdTZJhQEfy+wbQSt9zMWqs32kVksxz5cvOedRh50V7TamLtRjqNtBrpJLLSkTB3/aN5ojn+a3rGN9OGf7n6klc3a26+3tC8dSy/Frp3hdVvJ/z1iHt3g/VDvY7x43MFVSuAuz0QN6dQnTIaFY0OTXMgnb2g8Ynzds+zZstPuzdstOcLf0MnkaWOOIwghWhKRnidN+zSmrdpxVfDWQXj3ZLmnaO5ErqrQvs+428mdDvCMMI41kV6hGc8EBCrKzDFugp7j+SCd4pOGXOC7x2gTFvHkFd8vWmZkudyuaPfNFw2W/alredBdDx6xKt4yjfThl/vLnm13/Dq21Py+0D3jefkChavKxDttyPuZkTfb7G+p/RDjRsx/YCH7maZTuKEATIEVISwq6JwWtQzC3mhRAu8a5dMydG4zHVqiZ0jaKaVxGieoQS+6s943a/5zc2G7fUCfd3QvVcWr432vdG9zYTrCX+1r72Y/b5ukbtp9hMczfx4QA5eUgyTsaa7kpF9oOlHQtfQvFuQF1X/TAthPFmQuyW/Wp1jAf6xq5yEO3WK62sD2+/g2c5otoWwnQjXEbefkN2A9CM2DLXWOBzHzLd04FPY4zp3KdUHGahpGJCY8LngWo8bWkrraG58rTUWejyGafPBlyMgo+FHw+8Lvs+4fapA7EdkmLBhxGLt31pMn9Qr7trDO3dwe6o4JmQU6IdK/0NAnOJ9ZcXtgQ07Nytjd86o2eH00W2QPmayuQlld08wHw7o3nmOT2mP78sA2HymK2dMFEkJuyMtmt6eAoAPnD4CykEWmO/18Mud8+13M8j3+CGAT9eXuQvO4dnvCzUH6fF/HeMDafMzf9D6+/00xP3JPPLY9eewpw8Q3bMnQO6ZPP0zhO/ak4fcsydA7tkTIPfsCZB79gTIPXsC5J79D2NQSt6UYd6eAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#don't forget that show_image is a pytorch function that can show images stored as tensors\n",
        "show_image(mean_sevens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "qPhmE9n42a-_",
        "outputId": "95871fd6-89f4-4e34-88fb-bd04439e4f6a"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7faaaaf8b650>"
            ]
          },
          "metadata": {},
          "execution_count": 154
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let'spick and arbitrary 3 and check it's distance from our mean 3\n",
        "\n",
        "random_3 = random.choice(stacked_threes)\n",
        "random_to_mean_abs = (random_3-mean_threes).abs().mean()\n",
        "random_to_mean_sqrt = ((random_3-mean_threes)**2).mean().sqrt()\n",
        "(random_to_mean_abs,random_to_mean_sqrt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UVuGtAR2GnT",
        "outputId": "142ad44e-ee1e-4d70-81c2-2d975a54f247"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1207), tensor(0.2173))"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's check it against 7\n",
        "random_to_mean7_abs = (random_3-mean_sevens).abs().mean()\n",
        "random_to_mean7_sqrt = ((random_3-mean_sevens)**2).mean().sqrt()\n",
        "(random_to_mean7_abs,random_to_mean7_sqrt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4S-S4oEZmPI",
        "outputId": "7d475316-94c4-4736-f4d5-b9d1ba301d88"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1617), tensor(0.3079))"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Both cases our three and the mean 3 is less thatn the distance to the ideal 7 so that the  baseline algorithm would yield a good result in this case , but keep  in mind that there might be images of 3 who are closer to the mean of 7s that that of 3s"
      ],
      "metadata": {
        "id": "3bvhx33bbaCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pytorch has both of this function as loss function in its module torch.nn.functional ---- > loss function measures the discrepancy between the real value and the predicted value\n",
        "#the lower the loss function the better, now this is just for one image but we can calculate the loss for a bunch at once---tensor"
      ],
      "metadata": {
        "id": "avVvdC38qrCU"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "#takes as input a specific tensor and the target tensor\n",
        "#L1 norm = mean absolute value\n",
        "l1_3 = nn.functional.l1_loss(random_3,mean_threes)\n",
        "mse_3 =nn.functional.mse_loss(random_3,mean_threes)\n",
        "(l1_3,mse_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld5HD8wkbX6l",
        "outputId": "9cf5d60c-6881-4cee-ae51-a0173738eba6"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1207), tensor(0.0472))"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l1_7 = nn.functional.l1_loss(random_3,mean_sevens)\n",
        "mse_7 =nn.functional.mse_loss(random_3,mean_sevens)\n",
        "(l1_7,mse_7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIsmnhCGr058",
        "outputId": "adafcb15-34ab-43d6-fd24-234bf1bc71a7"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1617), tensor(0.0948))"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main difference between the L1 norm and the mse is that the latter will penalize bigger mistakes more heavily than the former.\n",
        "\n",
        "NumPy is the most widely used library for scientific and numeric programming in Python. It provides very similar functionality and a very similar API to that provided by PyTorch; however, it does not support using the GPU or calculating gradients, which are both critical for deep learning. Therefore, in this book we will generally use PyTorch tensors instead of NumPy arrays, where possible.\n",
        "\n",
        "Python is slow compared to many languages. Anything fast in Python, NumPy, or PyTorch is likely to be a wrapper for a compiled object written (and optimized) in another languagespecifically C. In fact, NumPy arrays and PyTorch tensors can finish computations many thousands of times faster than using pure Python.---> so they are most likely compiled C objects.\n",
        "\n",
        "A PyTorch tensor is nearly the same thing as a NumPy array, but with an additional restriction that unlocks some additional capabilities. It's the same in that it, too, is a multidimensional table of data, with all items of the same type.However, the restriction is that a tensor cannot use just any old typeit has to use a single basic numeric type for all components. For example, a PyTorch tensor cannot be jagged. It is always a regularly shaped multidimensional rectangular structure.To take advantage of its speed while programming in Python, try to avoid as much as possible writing loops, and replace them by commands that work directly on arrays or tensors.Perhaps the most important new coding skill for a Python programmer to learn is how to effectively use the array/tensor APIs. We will be showing lots more tricks later in this book, but here's a summary of the key things you need to know for now.\n",
        "The vast majority of methods and operators supported by NumPy on these structures are also supported by PyTorch, but PyTorch tensors have additional capabilities. One major capability is that these structures can live on the GPU, in which case their computation will be optimized for the GPU and can run much faster"
      ],
      "metadata": {
        "id": "Ed7rwv_8syUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_threes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1p9TRhJsyD2",
        "outputId": "c8033046-1e0a-48d2-c5eb-fef1f2746225"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This is how you can index a tensor, all tensors in the 3D tensors, the first till third line of each tensor and thier first till third column,\n",
        "#now you can watch each of them by indexing them further\n",
        "stacked_threes[:,1:3,1:3][0]\n",
        "\n",
        "#all other normal numpy operation can be done on a tensor or a group of tensor(higher order)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InPML6-PsUCV",
        "outputId": "a10509ab-f6e8-48c8-a7a0-215890d19eb3"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now to judge the quality of a model we must define and metric(quantity) whose value will let us know how good it is.a metric is a number that is calculated based on the predictions of our model, and the correct labels in our dataset.For instance, we could use either of the functions we saw in the previous section, mean squared error, or mean absolute error, and take the average of them over the whole dataset. However, neither of these are numbers that are very understandable to most people; in practice, we normally use accuracy as the metric for classification models.\n",
        "\n",
        "nomarly the metric is calculated over a validation set in order to avoid overfitting"
      ],
      "metadata": {
        "id": "mz4Ob-tA7L1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#let's stack the validation set images to in one tensor\n",
        "path.ls()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2o34cHX7KYV",
        "outputId": "be6b045b-11d3-41ff-a4a4-0641f3ab32b3"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [Path('train'),Path('labels.csv'),Path('valid')]"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(path/'valid').ls()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPzXyn7O8CEh",
        "outputId": "fbc945cf-d403-4dee-f4fa-45044f8bcdf4"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('valid/7'),Path('valid/3')]"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_set_7 =[ tensor(Image.open(o)).float()/255 for o in (path/'valid/7').ls()]\n",
        "validation_set_3 = [ tensor(Image.open(o)).float()/255 for o in (path/'valid/3').ls()]"
      ],
      "metadata": {
        "id": "MH63lb0L8U1V"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_tensor_7 = torch.stack(validation_set_7)\n",
        "valid_tensor_3 = torch.stack(validation_set_3)"
      ],
      "metadata": {
        "id": "0JtIwhLi8xG7"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(valid_tensor_3.shape,valid_tensor_7.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPI4SGaq9nin",
        "outputId": "bf2f6d7f-f94b-4e97-8544-0681d76ee560"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mnist_distance(a,b) :\n",
        "  #nn.functional.l1_loss(a,b)\n",
        "  return (a-b).abs().mean((-1,-2))\n",
        "#the (-1,-2) tells pytorch to execute the mean over the last two axis of our tensor that is the x and y of the image and not consider along the length of the tensor\n",
        "# that is why when you use an inbult nn.functional function it does not consider this pecularity and calculates the mean also over the length axis of the tensor and gives a scalar\n",
        "#tensor of dim = 0\n",
        "mnist_distance(random_3,mean_threes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL8AiTwXA_Et",
        "outputId": "bd32ecf3-3cc7-4fb1-b071-21a10504bd53"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1207)"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now we want to calculate the distance for all the validation tensor at once, this is where pytorch shines using broadcasting,\n",
        "#somehow broadcasting doesn't work with inbuild nn.funcitonal functions\n",
        "valid_3_dist = mnist_distance(valid_tensor_3,mean_threes)\n",
        "valid_3_dist, valid_3_dist.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym5UYeMjCLHa",
        "outputId": "e50ce8bb-1917-4dbf-9f1e-ff136a26068e"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.1238, 0.1378, 0.1258,  ..., 0.1108, 0.1303, 0.1120]),\n",
              " torch.Size([1010]))"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_7_dist = mnist_distance(valid_tensor_7,mean_sevens)\n",
        "valid_7_dist, valid_7_dist.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-ttDMhADRwz",
        "outputId": "f4bd0df0-ff75-4417-bb9a-c9f15dd54985"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0877, 0.1051, 0.1079,  ..., 0.1188, 0.1356, 0.0997]),\n",
              " torch.Size([1028]))"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a couple of important points about how broadcasting is implemented, which make it valuable not just for expressivity but also for performance:\n",
        "\n",
        "PyTorch doesn't actually copy mean3 1,010 times. It pretends it were a tensor of that shape, but doesn't actually allocate any additional memory\n",
        "It does the whole calculation in C (or, if you're using a GPU, in CUDA, the equivalent of C on the GPU), tens of thousands of times faster than pure Python (up to millions of times faster on a GPU!).\n",
        "This is true of all broadcasting and elementwise operations and functions done in PyTorch. It's the most important technique for you to know to create efficient PyTorch code."
      ],
      "metadata": {
        "id": "Pm5Dwj-OD6WK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#now we create a function that is going to tell us if an image is a 3 or not\n",
        "\n",
        "def is_3(image):\n",
        "  return mnist_distance(image, mean_threes) < mnist_distance(image, mean_sevens)\n"
      ],
      "metadata": {
        "id": "4KctHHzlFlhX"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's test it on a random_3 of the training set\n",
        "\n",
        "is_3(random.choice(stacked_threes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2DWOlAtGYli",
        "outputId": "3baa1c82-3c71-4920-924b-8b93127a4f2c"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now let's use it against our validation set\n",
        "is_3(valid_tensor_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MheqjhH_Gt4-",
        "outputId": "c87bfe3c-b9b5-41a8-82bf-3f56693c7c9e"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True,  ..., True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_3(valid_tensor_7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VVIah8yHOQ5",
        "outputId": "fe8016fa-f053-4bd5-e8f2-e769b3211282"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False, False, False,  ..., False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let'S define our metric based on this ---ACCURACY\n",
        "\n",
        "accuracy_3s = is_3(valid_tensor_3).float().mean()\n",
        "accuracy_7s = 1 - is_3(valid_tensor_7).float().mean()\n",
        "\n",
        "accuracy_3s , accuracy_7s,(accuracy_3s+accuracy_7s)/2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmbv2a7DHVel",
        "outputId": "b21ade08-b865-4896-9c4e-f917cc63a0cc"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.9168), tensor(0.9854), tensor(0.9511))"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**so  our baseline model has an accuracy of 0.9511, we are getting over 90% accuracy on both 3s and 7s**\n",
        "\n",
        "To do better, perhaps it is time to try a system that does some real learningthat is, that can automatically modify itself to improve its performance. In other words, it's time to talk about the training process, and SGD."
      ],
      "metadata": {
        "id": "fMxPK9LkH6xi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STOCHASTIC GRADIENT DESCENT(SGD)**"
      ],
      "metadata": {
        "id": "0LYsDk2fIcSI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose we arrange for some automatic means of testing the effectiveness of any current weight assignment in terms of actual performance and provide a mechanism for altering the weight assignment so as to maximize the performance. We need not go into the details of such a procedure to see that it could be made entirely automatic and to see that a machine so programmed would \"learn\" from its experience.this is the key to allowing us to have a model that can get better and betterthat can learn:But our pixel similarity approach does not really do this. We do not have any kind of weight assignment, or any way of improving based on testing the effectiveness of a weight assignment. In other words, we can't really improve our pixel similarity approach by modifying a set of parameters.Instead of trying to find the similarity between an image and an \"ideal image,\" we could instead look at each individual pixel and come up with a set of weights for each one, such that the highest weights are associated with those pixels most likely to be black for a particular category. For instance, pixels toward the bottom right are not very likely to be activated for a 7, so they should have a low weight for a 7, but they are likely to be activated for an 8, so they should have a high weight for an 8.\n",
        "\n",
        "\n",
        "So look at each pixel--> what is the probability that this particular pixel has to be relevant for a specific digit and we assign it the appropriate weight and we change this weights untill the error is minimal"
      ],
      "metadata": {
        "id": "4VXd2MupIopw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be more specific, here are the steps that we are going to require, to turn this function into a machine learning classifier:\n",
        "\n",
        "\n",
        "1.  Initialize the weights\n",
        "2.   For each image, use these weights to predict whether it appears to be a 3 or a 7.\n",
        "\n",
        "1.  Based on these predictions, calculate how good the model is (its loss).\n",
        "2.   Calculate the gradient, which measures for each weight, how changing that weight would change the loss\n",
        "\n",
        "1.   Step (that is, change) all the weights based on that calculation.\n",
        "2.   Go back to the step 2, and repeat the process.\n",
        "\n",
        "1.   Iterate until you decide to stop the training process (for instance, because the model is good enough or you don't want to wait any longer).\n",
        "\n",
        "\n",
        "These seven steps, illustrated in <>, are the key to the training of all deep learning models. That deep learning turns out to rely entirely on these steps is extremely surprising and counterintuitive. It's amazing that this process can solve such complex problems. But, as you'll see, it really does!\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2WNrcvYWLtm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#id gradient_descent\n",
        "#caption The gradient descent process\n",
        "#alt Graph showing the steps for Gradient Descent\n",
        "import graphviz as g\n",
        "t=g.Graph('''\n",
        "init->predict->loss->gradient->step->stop\n",
        "step->predict[label=repeat]\n",
        "''')\n",
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dh8xiuxInj5",
        "outputId": "de1fb001-71e9-4f32-eec0-1129bedb29f7"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "graph \"\n",
            "init->predict->loss->gradient->step->stop\n",
            "step->predict[label=repeat]\n",
            "\" {\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   We initialise the parameters to random values since our algorithm is going to improve it anyways\n",
        "2.   Loss : We need a function that will return the number that is small if the performance of the model is good \n",
        "1.   find out in which direction and by how much to change the weight untill we get a satisfactory weight overall(low lost function), the best way to do it is by using gradients\n",
        "2.  decide when to stop---e.g untill accuracy start getting worse or we run out of time.\n",
        "\n",
        "the procedure of gradient descent is the same always and is not changing the only way we can improve it is by adjusting the step\n",
        "\n",
        "For instance, the derivative of the quadratic function at the value 3 tells us how rapidly the function changes at the value 3. More specifically, you may recall that gradient is defined as rise/run, that is, the change in the value of the function, divided by the change in the value of the parameter. When we know how our function will change, then we know what we need to do to make it smaller.\n",
        "\n",
        "One important thing to be aware of is that our function has lots of weights that we need to adjust, so when we calculate the derivative we won't get back one number, but lots of thema gradient for every weight. But there is nothing mathematically tricky here; you can calculate the derivative with respect to one weight, and treat all the other ones as constant\n",
        "\n",
        "\n",
        "Amazingly enough, PyTorch is able to automatically compute the derivative of nearly any function! What's more, it does it very fast. Most of the time, it will be at least as fast as any derivative function that you can create by hand. Let's see an example.\n",
        "\n",
        "But in deep learning, \"gradients\" usually means the value of a function's derivative at a particular argument value.PyTorch API also puts the focus on the argument, not the function you're actually computing the gradients of. It may feel backwards at first, but it's just a different perspective.\n",
        "\n",
        "backpropagation, which is the name given to the process of calculating the derivative of each layer.This is called the \"backward pass\" of the network, as opposed to the \"forward pass,\" which is where the activations are calculated. Life would probably be easier if backward was just called calculate_grad, but deep learning folks really do like to add jargon everywhere they can!\n",
        "\n"
      ],
      "metadata": {
        "id": "Au7t2gDjUbiK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Understanding SGD***"
      ],
      "metadata": {
        "id": "_FaVgYn5Vj8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x) : return x**2"
      ],
      "metadata": {
        "id": "BWUrXM3AUEuu"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#here is the standard procedure for calculating the gradient at a specific point \n",
        "#in pytorch when we want to calculate the  gradient at a specific point (value of the gradient)\n",
        "value =3.\n",
        "#1- we stick the gradient to that variable\n",
        "xt = tensor(value).requires_grad_() #----  variable : find gradient at point with value 3\n",
        "yt = f(xt) # apply the request to the function\n",
        "yt.backward()  # calculat it\n",
        "xt.grad\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-NqpAwSV5zQ",
        "outputId": "52148cba-9705-4799-a713-47833753aa87"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gradients only tell us the slope of our function, they don't actually tell us exactly how far to adjust the parameters. But it gives us some idea of how far; if the slope is very large, then that may suggest that we have more adjustments to do, whereas if the slope is very small, that may suggest that we are close to the optimal value."
      ],
      "metadata": {
        "id": "VxcS2wUIZ_zT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stepping With a Learning Rate**\n",
        "\n",
        "Deciding how to change our parameters based on the values of the gradients is an important part of the deep learning process. Nearly all approaches start with the basic idea of multiplying the gradient by some small number, called the learning rate (LR)\n",
        "The learning rate is often a number between 0.001 and 0.1, although it could be anything. Often, people select a learning rate just by trying a few, and finding which results in the best model after training (we'll show you a better approach later in this book, called the learning rate finder)\n",
        "\n"
      ],
      "metadata": {
        "id": "XSCA4RShaCro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#once the learning rate has been chosen we adjust our weight by using a simple function\n",
        "\n",
        "#w = w -lr* gr(w)\n",
        "\n",
        "#this is nknown as the optimizer step --- parameter update This allows us to adjust the parameter in the direction of the slope \n",
        "#by increasing the parameter when the slope is negative and decreasing the parameter when the slope is positive.\n",
        "# We want to adjust our parameters in the direction of the slope because our goal in deep learning is to minimize the loss.\n",
        "#If the learning rate is too high, it may also \"bounce\" around, rather than actually diverging;\n",
        "#this has the result of taking many steps to train successfully."
      ],
      "metadata": {
        "id": "XNyz5oqnVsjv"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#example ---- > let's fint he best quadratic function that approximates a certain velocity behavior defined by\n",
        "\n",
        "\n",
        "time = torch.arange(0,20).float();\n",
        "time\n",
        "#randn return a set of n random number from a normal distribution\n",
        "speed = torch.randn(20)*3 + 0.75*(time-9.5)**2 + 1 "
      ],
      "metadata": {
        "id": "G56eZ92tjuJV"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(time,speed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "KfaAZlTUkEsg",
        "outputId": "f5683e6d-f9ff-4053-b79f-09b93a8729a6"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7faaaa050bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 180
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we wan to distinguish between the function's input and its parameters, the values that define which quadratic we're trying\n",
        "\n",
        "def f(t, params):\n",
        "  #t = input params =parameter\n",
        "  a,b,c= params\n",
        "  return a*(t**2)+(b*t)+c\n",
        "\n",
        "  #since every quadratic function is fully defined by the three parameters a, b, and c. Thus, to find the best quadratic function, we only need to find the best values for a, b, and c.\n",
        "  #We need to define first what we mean by \"best.\" We define this precisely by choosing a loss function,For continuous data, it's common to use mean squared error:\n",
        "\n",
        "  def mse(preds, targets):\n",
        "    return ((preds-targets)**2).mean()"
      ],
      "metadata": {
        "id": "xRjIQbHosHYm"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 1 \n",
        "#initialize the parameters randomly a,b,c\n",
        "##reminds pytorch that they will be requiring the gradient at this weights\n",
        "params = torch.randn(3).requires_grad_()\n",
        "orig_params=params.clone()"
      ],
      "metadata": {
        "id": "CJ425B5sugt9"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 2 calculate the prediction\n",
        "\n",
        "preds=f(time,params)"
      ],
      "metadata": {
        "id": "rIog1SNxuzH9"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_preds(preds,ax=None):\n",
        " if ax is None: ax=plt.subplots()[1]\n",
        " ax.scatter(time,speed)\n",
        " ax.scatter(time,to_np(preds),color ='red')\n",
        " ax.set_ylim(-300,100)"
      ],
      "metadata": {
        "id": "ZuTXtH_MvLdN"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_preds(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "PccCrwnMvohc",
        "outputId": "9aec344f-fa3a-4e13-b0c3-d35080a2c772"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the loss\n",
        "\n",
        "loss = mse(preds,speed)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ura2OdcZwJTD",
        "outputId": "cea2427f-6ea4-41d8-d090-9a72df70e5dd"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorBase(84908.7344, grad_fn=<AliasBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the gradient of the loss function according to the parameters\n",
        "loss.backward()\n",
        "params.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9HXM0lXwdEV",
        "outputId": "2202210b-4b8d-43bd-ab9f-1043997ac8c5"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-97354.4844,  -6253.1025,   -447.8495])"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params.grad*1e-5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RGr1zOKw32s",
        "outputId": "7b3438f9-03f8-4fa7-c795-bc1cf6283f90"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.9735, -0.0625, -0.0045])"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's  use these gradients to improve our parameters, let's pic 1e-5 as learning rate\n",
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYEpPpjPw7Ry",
        "outputId": "0ab4e582-d5b7-4e08-ca56-3bed8cf8eb5e"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.5500, -0.7509,  0.8372], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step the weights\n",
        "\n",
        "lr= 1e-5\n",
        "params.data -= lr*params.grad.data\n",
        "params.grad = None"
      ],
      "metadata": {
        "id": "mvHeMG0axQ91"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the loss again\n",
        "preds = f(time,params)\n",
        "mse(preds,speed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9lfquk-zn6-",
        "outputId": "ce8a6294-c3d5-452c-c9f5-9790c100b173"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorBase(16622.5430, grad_fn=<AliasBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_preds(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "xDoEyXkSzyiv",
        "outputId": "cd38c9d6-4f69-4639-d85f-23ef47a404da"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we can see indeed that the function draws closer to our original function\n",
        "\n",
        "def apply_step (params, prn=True):\n",
        "  preds = f(time, params)\n",
        "  loss = mse(preds,speed)\n",
        "  loss.backward()\n",
        "  params.data -=lr*params.grad.data\n",
        "  params.grad = None\n",
        "  if prn: print(loss.item()) \n",
        "  return preds"
      ],
      "metadata": {
        "id": "g7dQg_7nz9sw"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):apply_step(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWrj0X2Q07Rl",
        "outputId": "1b2ff560-4f1c-4b9a-d249-a285151b90ee"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16622.54296875\n",
            "3700.715576171875\n",
            "1255.5068359375\n",
            "792.7952880859375\n",
            "705.232666015625\n",
            "688.6595458984375\n",
            "685.52001953125\n",
            "684.9224853515625\n",
            "684.8057250976562\n",
            "684.7802124023438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.randn(3).requires_grad_()\n",
        "orig_params=params.clone()\n",
        "params=orig_params.detach().requires_grad_()"
      ],
      "metadata": {
        "id": "SJbUM1RO33aK"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_,axs = plt.subplots(1,4,figsize=(12,3))\n",
        "for ax in axs: \n",
        "  show_preds(apply_step(params,False),ax)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "p5meNjuo1Lol",
        "outputId": "fa19a262-99d4-4b59-8bfc-e67965655a3a"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x216 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stop\n",
        "#we decided to stop arbitrarily after 10 epochs, in practice, we would watch the training and validation losses and our metrics to decide when to stop"
      ],
      "metadata": {
        "id": "0IKFWRFW4ukj"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To summarize, at the beginning, the weights of our model can be random (training from scratch) or come from a pretrained model (transfer learning). In the first case, the output we will get from our inputs won't have anything to do with what we want, and even in the second case, it's very likely the pretrained model won't be very good at the specific task we are targeting. So the model will need to learn better weights.\n",
        "\n",
        "We begin by comparing the outputs the model gives us with our targets (we have labeled data, so we know what result the model should give) using a loss function, which returns a number that we want to make as low as possible by improving our weights.\n",
        "\n",
        "\n",
        "To do this, we take a few data items (such as images) from the training set and feed them to our model. We compare the corresponding targets using our loss function, and the score we get tells us how wrong our predictions were. We then change the weights a little bit to make it slightly better.\n",
        "\n",
        "\n",
        "Let's consider an analogy. Imagine you are lost in the mountains with your car parked at the lowest point. To find your way back to it, you might wander in a random direction, but that probably wouldn't help much. Since you know your vehicle is at the lowest point, you would be better off going downhill. By always taking a step in the direction of the steepest downward slope, you should eventually arrive at your destination.\n",
        "\n",
        "We use the magnitude of the gradient (i.e., the steepness of the slope) to tell us how big a step to take; specifically, we multiply the gradient by a number we choose called the learning rate to decide on the step size.\n",
        "\n"
      ],
      "metadata": {
        "id": "yxLYAv7O5BwZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The MNIST Loss Function**"
      ],
      "metadata": {
        "id": "VC--G8JC5mOO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We already have our independent variables xthese are the images themselves. We'll concatenate them all into a single tensor, and also change them from a list of matrices (a rank-3 tensor) to a list of vectors (a rank-2 tensor). We can do this using view, which is a PyTorch method that changes the shape of a tensor without changing its contents."
      ],
      "metadata": {
        "id": "gQM-Z1k2Fhe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#that means we explode every image  from matrix to vector of length(28*28), so all the pixels in one long array\n",
        "#reshape is an another option\n",
        "train_x = torch.cat([stacked_threes,stacked_sevens]).view(-1,28*28)"
      ],
      "metadata": {
        "id": "gu-ez1Re5u-O"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x.shape[0] == stacked_threes.shape[0] + stacked_sevens.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnghTTjlGeh_",
        "outputId": "5b7c44c4-6275-43ef-fd87-8e0a5fbc22da"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x.shape[1] == stacked_threes.shape[1]*stacked_threes.shape[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1e7de2c-4fbf-4c79-e5c5-34a339024664",
        "id": "L__XVyPmG9aJ"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we create the labels for each image 1 for 3s and 0 for 7s\n",
        "\n",
        "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
        "train_x.shape, train_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsY5JMK9HGp2",
        "outputId": "ae520ed9-2725-493f-927c-b6fbae44f1b3"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([12396, 784]), torch.Size([12396, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we create our training dataset which to each image associates a label\n",
        "dset = list(zip(train_x,train_y))\n",
        "x,y = dset[0]\n",
        "x.shape, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmrPonwMG2Nk",
        "outputId": "ff4f9cd2-f1e9-419f-b0b9-103472d55bd8"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784]), tensor([1]))"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we create our validation dataset in the same format\n",
        "\n",
        "valid_x = torch.cat([valid_tensor_3,valid_tensor_7]).view(-1,28*28)\n",
        "valid_y = tensor([1]*len(validation_set_3) + [0]*len(validation_set_7)).unsqueeze(1)\n",
        "valid_dset = list(zip(valid_x,valid_y))\n"
      ],
      "metadata": {
        "id": "wxj74gbBMYwf"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step-1 initialising the parameters\n",
        "\n",
        "def init_params(size, std=1.0):\n",
        "  return (torch.randn(size)*std).requires_grad_()"
      ],
      "metadata": {
        "id": "kKhuk4UCNThG"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the weights for one single image??\n",
        "weights = init_params((28*28,1))"
      ],
      "metadata": {
        "id": "N4qd1svkZWBj"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bias = init_params(1)"
      ],
      "metadata": {
        "id": "8uCPnAuLNhab"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we can now calculate the prediction of one single image\n",
        "#w*X+b\n",
        "#In neural networks, the w in the equation y=w*x+b is called the weights, and the b is called the bias. Together, the weights and bias make up the parameters.\n",
        "(train_x[0]*weights.T).sum()+bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ktyd04k3Zv3x",
        "outputId": "747ac068-72cb-4dd7-d768-f1283115e4ea"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([19.6227], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#while we could use python  for loop to calculate the prediction for all the image, that would be very slow because python loops don't run on GPU:nd because Python is a slow language for loops in general,\n",
        "#we need to represent as much of the computation in a model as possible using higher-level functions.\n",
        "#Matrix Multiplication is the most important mathematical operation in deep learning.\n",
        "#In Python, matrix multiplication is represented with the @ operator. Let's try it:\n",
        "\n",
        "\n",
        "def linear1(xb):\n",
        "  return xb@weights + bias\n"
      ],
      "metadata": {
        "id": "gWdbQEYnaJeC"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this takes the whole training tensor made up of 12396 vectors of 784 representing each an image and multiplies it with the weight vector --- broadcasting\n",
        "#and adds for each the bias, we get a rank-2 tensor as well with the prediction for each images\n",
        "preds = linear1(train_x)\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTT4UYy5cszL",
        "outputId": "1558307e-4eb1-4736-c148-dcd0d7ab18b3"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[19.6227],\n",
              "        [12.4130],\n",
              "        [ 0.1864],\n",
              "        ...,\n",
              "        [-0.6078],\n",
              "        [ 6.4030],\n",
              "        [ 5.1042]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking our accuracy\n",
        "\n",
        "correctly_predicted = (preds>0.0).float() == train_y\n",
        "correctly_predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcJbrPLcdG0Q",
        "outputId": "d24f00a7-12ac-4a24-fc84-35455348c1f7"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ True],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        ...,\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False]])"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy\n",
        "correctly_predicted.float().mean()\n",
        "#our accuracy is 0.5--- > which is basically  equal to a random experiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UT4BlVmdpZs",
        "outputId": "b8c9d636-7fa3-4d13-f5ca-68454ed2f426"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4875)"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now we need a loss function to calculate the gradient as they measure how this loss function changes if we tweak the weights\n",
        "#The gradient of a function is its slope, or its steepness, which can be defined as rise over runthat is, how much the value of the function goes up or down, divided by how much we changed the input. We can write this in mathematically as: (y_new - y_old) / (x_new - x_old).\n",
        "#A very small change in the value of a weight will often not actually change the accuracy at all. This means it is not useful to use accuracy as a loss functionif we do, most of the time our gradients will actually be 0, and the model will not be able to learn from that number.\n",
        "#In mathematical terms, accuracy is a function that is constant almost everywhere (except at the threshold, 0.5), so its derivative is nil almost everywhere (and infinity at the threshold). This then gives gradients that are 0 or infinite, which are useless for updating the model."
      ],
      "metadata": {
        "id": "8saBvNSOeOgx"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss function receives not the images themselves, but the predictions from the model. Let's make one argument, prds, of values between 0 and 1, where each value is the prediction that an image is a 3. It is a vector (i.e., a rank-1 tensor), indexed over the images.The purpose of the loss function is to measure the difference between predicted values and the true values  that is, the targets (aka labels). Let's make another argument, trgts, with values of 0 or 1 which tells whether an image actually is a 3 or not. It is also a vector (i.e., another rank-1 tensor), indexed over the images.\n",
        "\n",
        "One problem with mnist_loss as currently defined is that it assumes that predictions are always between 0 and 1. We need to ensure, then, that this is actually the case! As it happens, there is a function that does exactly thatlet's take a look.The sigmoid function always outputs a number between 0 and 1. It's defined as follows:Pytorch defines an accelerated version for us, so we dont really need our own. This is an important function in deep learning, since we often want to ensure values are between 0 and 1. This is what it looks like:"
      ],
      "metadata": {
        "id": "3_CUpMeLjBk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The key difference is that the metric is to drive human understanding and the loss is to drive automated learning**\n",
        "To drive automated learning, the loss must be a function that has a meaningful derivative. It can't have big flat sections and large jumps, but instead must be reasonably smooth. This is why we designed a loss function that would respond to small changes in confidence level.Metrics, on the other hand, are the numbers that we really care about. These are the values that are printed at the end of each epoch that tell us how our model is really doing. It is important that we learn to focus on these metrics, rather than the loss, when judging the performance of a model.\n",
        "\n",
        "\n",
        "Now that we have a loss function that is suitable for driving SGD, we can consider some of the details involved in the next phase of the learning process, which is to change or update the weights based on the gradients--- this is the optimization step\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-shrYzZ-xtdE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So instead we take a compromise between the two: we calculate the average loss for a few data items at a time. This is called a mini-batch. The number of data items in the mini-batch is called the batch size. so we take a couple of images like 20 of them we calculate the loss for each of thema and average it over 20\n",
        "A larger batch size means that you will get a more accurate and stable estimate of your dataset's gradients from the loss function, but it will take longer, and you will process fewer mini-batches per epoch.  an Epoch is a complete run through of the dataset.Choosing a good batch size is one of the decisions you need to make as a deep learning practitioner to train your model quickly and accurately. We will talk about how to make this choice throughout this book.Another good reason for using mini-batches rather than calculating the gradient on individual data items is that, in practice, we nearly always do our training on an accelerator such as a GPU. These accelerators only perform well if they have lots of work to do at a time, so it's helpful if we can give them lots of data items to work on.\n",
        "\n",
        "Rather than simply enumerating our dataset in order for every epoch, instead what we normally do is randomly shuffle it on every epoch, before we create mini-batches. PyTorch and fastai provide a class that will do the shuffling and mini-batch collation for you, called DataLoader.\n",
        "\n",
        "A DataLoader can take any Python collection and turn it into an iterator over mini-batches, like so:"
      ],
      "metadata": {
        "id": "07THGcUMdZ4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coll = range(15)\n",
        "dl = DataLoader(coll, batch_size=5, shuffle = True)\n",
        "list(dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9qNSNfqxs-u",
        "outputId": "0f724f39-b376-413e-bee8-d7d18bb599c7"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([ 0,  7,  4,  5, 11]),\n",
              " tensor([ 9,  3,  8, 14,  6]),\n",
              " tensor([12,  2,  1, 10, 13])]"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A collection that contains tuples of independent and dependent variables is known in PyTorch as a Dataset."
      ],
      "metadata": {
        "id": "VetXgl-4pvF3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ws1rREhqpt3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset is a collection of tuples of tensors in one tuple we have an image and its label\n",
        "dset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iil2Aj4bpten",
        "outputId": "638fea41-4845-483f-dd0c-22b485490a2f"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.1647, 0.4627, 0.8588, 0.6510, 0.4627, 0.4627, 0.0235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4039, 0.9490, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.2588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.9098, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9333, 0.2745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4078, 0.9569, 0.9961, 0.8784, 0.9961, 0.9961, 0.9961, 0.5529, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8118, 0.9961, 0.8235, 0.9961,\n",
              "         0.9961, 0.9961, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.3294, 0.8078, 0.9961, 0.9961, 0.9961, 0.9961, 0.1608, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941, 0.8196, 0.9961, 0.9961, 0.9961, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3569, 0.5373, 0.9922, 0.9961, 0.9961, 0.9961, 0.4392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569, 0.8392, 0.9804, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9686, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.5725, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4314, 0.9647, 0.9961, 0.9961, 0.9961,\n",
              "         0.9961, 0.9961, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.2863, 0.3490, 0.3490, 0.3647, 0.9412, 0.9961, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.5020, 0.9961, 0.8588, 0.1216, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275, 0.9961, 0.9961, 0.8392, 0.1098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5412, 0.9961, 0.9961, 0.4549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.6941, 0.3529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980, 0.9412, 0.9961, 0.9961, 0.1333, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6431, 0.9961, 0.8431, 0.2471, 0.1412, 0.0000, 0.2000, 0.3490, 0.8078, 0.9961,\n",
              "         0.9961, 0.5451, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2235, 0.7725, 0.9961, 0.9961, 0.8706, 0.7059,\n",
              "         0.9451, 0.9961, 0.9961, 0.9922, 0.8353, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5490,\n",
              "         0.4118, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0275, 0.4588, 0.4588, 0.6471, 0.9961, 0.9961, 0.9373, 0.1961, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]),\n",
              " tensor([1]))"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Puting it all together\n",
        "\n",
        "#itialising weights \n",
        "weights = init_params((28*28,1))\n",
        "bias= init_params(1)"
      ],
      "metadata": {
        "id": "NwQVBKozrVXS"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mnist_loss(predictions, targets):\n",
        "    return torch.where(targets==1, 1-predictions, predictions).mean()#create a DataLoader for training set --- for creating mini-batches out of dataset\n",
        "dl = DataLoader(dset, batch_size=256)\n",
        "xb,yb = first(dl)\n",
        "xb.shape, yb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKY7C8pJr0gm",
        "outputId": "797b7cb2-4ac2-418f-83ff-01e963d54ea0"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([256, 784]), torch.Size([256, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create DataLoader  for validation set\n",
        "\n",
        "valid_dl = DataLoader(valid_dset,batch_size=256)"
      ],
      "metadata": {
        "id": "XqHZkI5esNsa"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's create a mini-batch of size 4 for testing\n",
        "\n",
        "batch_4 = train_x[:4]\n",
        "batch_4.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlDlHsBXtDRH",
        "outputId": "e8185949-cb11-418d-fe6d-18096bac8c57"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's perform predictions on our mini patch\n",
        "#it's gonna return the prediction for each of the images in the batch\n",
        "preds = linear1(batch_4)\n",
        "preds\n",
        "#shouldn't we make sure that the predictions are between 0 and 1 ? by using the sigmoid?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxQfwhYptYh8",
        "outputId": "314f3827-52ee-44f9-a0a4-d983db3de324"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-4.4922],\n",
              "        [-6.5688],\n",
              "        [-7.9150],\n",
              "        [ 1.6136]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#squishes the function between 0 and 1\n",
        "def sigmoid(x): return 1/(1+torch.exp(-x))\n",
        "\n",
        "def mnist_loss(predictions, targets):\n",
        "    predictions = predictions.sigmoid()\n",
        "    return torch.where(targets==1, 1-predictions, predictions).mean()"
      ],
      "metadata": {
        "id": "lQ9z0hgRwk-h"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the average loss for this mini-batch\n",
        "\n",
        "loss = mnist_loss(preds, train_y[:4])\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hnxMwAiv7-8",
        "outputId": "a36508a6-6315-483f-a6b8-f133e3313a57"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7883, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the gradients for all of the pixels for all of the images of the mini_batch\n",
        "#we can do this because when initialising the parameters we already indicated that they would require gradient calculation later\n",
        "loss.backward()\n",
        "weights.grad.shape, weights.grad.mean(),bias.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rovRGPBoxZMA",
        "outputId": "7364364c-2851-4c80-e3f0-2dde78eded26"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784, 1]), tensor(-0.0065), tensor([-0.0378]))"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#puting all in a function\n",
        "\n",
        "def calc_grad (xb,yb,model):\n",
        "  preds = model(xb)\n",
        "  loss = mnist_loss(preds,yb)\n",
        "  loss.backward()"
      ],
      "metadata": {
        "id": "EmB19LX13ysV"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_grad(batch_4,train_y[:4],linear1)\n",
        "weights.grad.mean(), bias.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbaWB5Hs4DHw",
        "outputId": "a4ac0183-8c63-49bf-e906-3eff91461c3b"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0131), tensor([-0.0756]))"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we have to set the the current gradient to 0 first before calculating the gradients again otherwise they\n",
        "#will be added up to the existing ones\n",
        "# inplace operations in pytorch finish with and  _\n",
        "weights.grad.zero_()\n",
        "bias.grad.zero_()\n",
        "#now we have to update our weights with the appropriate learning rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P40UwlPA4kJY",
        "outputId": "872609d9-9f62-4e46-ac2f-df3094469cbf"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.])"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here is the training for an epoch\n",
        "#one weight vector for a batch\n",
        "#params are weights and bias (initial)\n",
        "def train_epoch(model, lr, params):\n",
        "  #for every batch in the data loader\n",
        "  for(xb,yb) in dl:\n",
        "    calc_grad(xb,yb,model)\n",
        "    for p in params:\n",
        "      p.data -=p.grad*lr\n",
        "      p.grad.zero_()\n",
        "\n",
        "def batch_accuracy(xb,yb):\n",
        "  preds = xb.sigmoid()\n",
        "  correct = (preds>0.5).float() == yb\n",
        "  return correct.float().mean()\n",
        "#put all the ebatches together\n",
        "def validate_epoch(model):\n",
        "  accs= [batch_accuracy(model(xb),yb) for xb,yb in valid_dl]\n",
        "  return round(torch.stack(accs).mean().item(),4)\n"
      ],
      "metadata": {
        "id": "5OcMGaNd5G9j"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate_epoch(linear1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MOA0QVy8Cq3",
        "outputId": "2cdf423e-6eb1-495e-c0d8-56bd82504c37"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4734"
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#choose the learning rate\n",
        "lr=1.\n",
        "#initialise the weights and bias\n",
        "params=weights,bias\n",
        "#train for a full epoch == modify the the weights once for all the batches of an epoch\n",
        "train_epoch(linear1,lr,params)\n",
        "#check how good the model is - against the validation dataset at this level after having modified all the weights\n",
        "validate_epoch(linear1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGaCn9MA8Y1h",
        "outputId": "4abfb9c2-5a67-46d2-9190-85fe559ff252"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5945"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now repeat this over an over --- many epoch --at every epoch , shuffle and redistribute the batches\n",
        "#for now simply repeat on the same batch distribution\n",
        "\n",
        "for i in range(20):\n",
        "  train_epoch(linear1,lr,params)\n",
        "  print(validate_epoch(linear1), end=\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-ADjSvX9vDq",
        "outputId": "502c0584-e9ea-4d16-f990-3e6ce4c6bc0b"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7996 0.8816 0.9104 0.9285 0.9363 0.9461 0.9495 0.9529 0.9559 0.9578 0.9593 0.9603 0.9603 0.9612 0.9632 0.9632 0.9642 0.9647 0.9661 0.9666 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now we create and OPTIMIZER --- which is simply a fancy name for function that handles the SGD for us"
      ],
      "metadata": {
        "id": "rm5jb3dZ-Q5a"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first thing we can do is replace our linear1 function with PyTorch's nn.Linear module. A module is an object of a class that inherits from the PyTorch nn.Module class. Objects of this class behave identically to standard Python functions, in that you can call them using parentheses and they will return the activations of a model.\n",
        "\n",
        "nn.Linear does the same thing as our init_params and linear together. It contains both the weights and biases in a single class\n",
        "\n",
        "so nn.Linear initialises the weights and bias and creates a linear model to approximate our image, so there is a linear function between an image and it's class and tweaking the parameters will help us approximate that function so we start by randomly attributing the weights\n"
      ],
      "metadata": {
        "id": "cXRdzaZpByMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model = nn.Linear(28*28,1)\n",
        "w,b =linear_model.parameters()\n",
        "w.shape, b.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWINR6xOCVQw",
        "outputId": "c5e1b158-04d9-47f2-9fda-0471ccaa385a"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 784]), torch.Size([1]))"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicOptimzer:\n",
        "  def __init__(self,params,lr):\n",
        "    self.params, self.lr  = list(params),lr\n",
        "  def step(self,*args,**kwargs):\n",
        "    for p in self.params :\n",
        "      p.data -= p.grad.data * self.lr\n",
        "  def zero_grad(self,*args,**kwargs):\n",
        "    for p in self.params: p.grad = None"
      ],
      "metadata": {
        "id": "A9fuXnzjCndi"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now we can create an optimzer and use it in our epoch training\n",
        "#of course fastai and pytorch have inbuilt optmizers that we can use ---- > basically calculat the step, adjust the weights and reinitialises them for the next step\n",
        "optimizer = BasicOptimzer(linear_model.parameters(),lr)"
      ],
      "metadata": {
        "id": "Y8X666ZLFcMr"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we redefine train_epoch to use the optimizer\n",
        "def train_epoch(model):\n",
        "  #for every batch in the data loader\n",
        "  for(xb,yb) in dl:\n",
        "    calc_grad(xb,yb,model)\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "nzKs7QkCGzAD"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate_epoch(linear_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFxrK_LaHO0l",
        "outputId": "c286d9b8-1066-461c-87fc-864e6a54ebba"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5465"
            ]
          },
          "metadata": {},
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define a general function that is going to train the model over a given number of epochs\n",
        "def train_model(model, epochs):\n",
        "  for i in range(epochs):\n",
        "    train_epoch(model)\n",
        "    print(validate_epoch(model), end=' ')"
      ],
      "metadata": {
        "id": "LA4V79DGHVF4"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(linear_model,20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHfVXUwpH79G",
        "outputId": "e3f05bb6-0551-4d32-a00b-e7f0ad87ffaf"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4932 0.7725 0.8594 0.9189 0.9365 0.9512 0.9585 0.9638 0.9663 0.9677 0.9702 0.9721 0.9741 0.9755 0.976 0.9765 0.978 0.978 0.978 0.9785 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fastai also provides a function for training the model out of the box so that we don't need to \n",
        "#rewrite them, for that we need a data loader \n",
        "#A Data loader takes the training set as well as the validation set  and create minibatches\n",
        "#dl = dl = DataLoader(dset, batch_size=256)------->\n",
        "#valid_dl = DataLoader(valid_dset,batch_size=256)------>\n",
        "#valid_x = torch.cat([valid_tensor_3,valid_tensor_7]).view(-1,28*28)\n",
        "#valid_y = tensor([1]*len(validation_set_3) + [0]*len(validation_set_7)).unsqueeze(1)\n",
        "#valid_dset = list(zip(valid_x,valid_y))\n",
        "#dset = list(zip(train_x,train_y))\n",
        "#beware DataLoaders takes the training and validation and DataLoader just one and creates batches\n",
        "dls = DataLoaders(dl , valid_dl)"
      ],
      "metadata": {
        "id": "2v6S9qBgIqaa"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a learner \n",
        "\n",
        "learn = Learner(dls,nn.Linear(28*28,1),opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy )"
      ],
      "metadata": {
        "id": "4r4b1XLSPxxL"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit(10,lr=lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "bO5An9tOQhIP",
        "outputId": "bccf2716-747f-4ab7-fc97-17132da1e919"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>batch_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.637487</td>\n",
              "      <td>0.503007</td>\n",
              "      <td>0.495584</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.406030</td>\n",
              "      <td>0.298656</td>\n",
              "      <td>0.703631</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.154219</td>\n",
              "      <td>0.160429</td>\n",
              "      <td>0.857213</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.070189</td>\n",
              "      <td>0.099800</td>\n",
              "      <td>0.916585</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.039053</td>\n",
              "      <td>0.074377</td>\n",
              "      <td>0.934249</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.026770</td>\n",
              "      <td>0.060269</td>\n",
              "      <td>0.948479</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.021637</td>\n",
              "      <td>0.051354</td>\n",
              "      <td>0.956820</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.019293</td>\n",
              "      <td>0.045370</td>\n",
              "      <td>0.963199</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.018060</td>\n",
              "      <td>0.041142</td>\n",
              "      <td>0.965653</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.017292</td>\n",
              "      <td>0.038015</td>\n",
              "      <td>0.968597</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, there's nothing magic about the PyTorch and fastai classes. They are just convenient pre-packaged pieces that make your life a bit easier! (They also provide a lot of extra functionality we'll be using in future chapters.)With these classes, we can now replace our linear model with a neural network."
      ],
      "metadata": {
        "id": "C2bneylET7bE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far we have a general procedure for optimizing the parameters of a function, and we have tried it out on a very boring function: a simple linear classifier. A linear classifier is very constrained in terms of what it can do. To make it a bit more complex (and able to handle more tasks), we need to add something nonlinear between two linear classifiersthis is what gives us a neural network."
      ],
      "metadata": {
        "id": "_lrDoe1_UEBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_net(xb): \n",
        "    res = xb@w1 + b1\n",
        "    res = res.max(tensor(0.0))\n",
        "    res = res@w2 + b2\n",
        "    return res\n",
        "#That's it! All we have in simple_net is two linear classifiers with a max function between them.\n",
        "#Here, w1 and w2 are weight tensors, and b1 and b2 are bias tensors; that is, parameters that are initially randomly initialized, just like we did in the previous section:\n",
        "\n",
        "w1 = init_params((28*28,30))\n",
        "b1 = init_params(30)\n",
        "w2 = init_params((30,1))\n",
        "b2 = init_params(1)\n",
        "\n",
        "#The key point about this is that w1 has 30 output activations (which means that w2 must have 30 input activations, so they match\n",
        "#That means that the first layer can construct 30 different features, each representing some different mix of pixels. You can change that 30 to anything you like, to make the model more or less complex.\n",
        "\n",
        "#The three lines of code that we have here are known as layers. The first and third are known as linear layers, and the second line of code is known variously as a nonlinearity, or activation function.\n"
      ],
      "metadata": {
        "id": "zVd0s8FPT6XN"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So this is how features are found, like edges etc...we take bunch of images as tensors exploded and they go through a linear function that combines them with a weight vector/matrix and outputs 30 or more rank-1 or rank-n tensors  whhich represent a specific feature extracted from the image. That little function res.max(tensor(0.0)) is called a rectified linear unit, also known as ReLU. We think we can all agree that rectified linear unit sounds pretty fancy and complicated... But actually, there's nothing more to it than res.max(tensor(0.0))in other words, replace every negative number with a zero. This tiny function is also available in PyTorch as F.relu:\n",
        "\n",
        "\n",
        "But if we put a nonlinear function between them, such as max, then this is no longer true. Now each linear layer is actually somewhat decoupled from the other ones, and can do its own useful work. The max function is particularly interesting, because it operates as a simple if statement.\n",
        "\n",
        "\n",
        "For any arbitrarily wiggly function, we can approximate it as a bunch of lines joined together; to make it closer to the wiggly function, we just have to use shorter lines. This is known as the universal approximation theorem. The three lines of code that we have here are known as layers. The first and third are known as linear layers, and the second line of code is known variously as a nonlinearity, or activation function.  \n",
        "\n",
        "think of layers as short lines joined with some rate of non linearity that wiggles it left or right to produce the arbitrary function"
      ],
      "metadata": {
        "id": "4jIPo73cWH4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we recreate our model now\n",
        "#first linear classifier with 28*28 inputs and 30 outputs\n",
        "#second linear classifier with 30 input and 1 output\n",
        "simple_net = nn.Sequential(\n",
        "    nn.Linear(28*28,30),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(30,1)\n",
        ")"
      ],
      "metadata": {
        "id": "jwAv5luSV1aj"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls,simple_net,opt_func=SGD,loss_func=mnist_loss, metrics=batch_accuracy )"
      ],
      "metadata": {
        "id": "KW_-n1frdp-n"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit(40,0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lu8f_QhMd4fH",
        "outputId": "b608d4ea-a007-4d40-a502-196e9f7e60d6"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>batch_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.021549</td>\n",
              "      <td>0.025251</td>\n",
              "      <td>0.975957</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.018176</td>\n",
              "      <td>0.023115</td>\n",
              "      <td>0.977920</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.016797</td>\n",
              "      <td>0.022587</td>\n",
              "      <td>0.979882</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.016160</td>\n",
              "      <td>0.022426</td>\n",
              "      <td>0.979882</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.015822</td>\n",
              "      <td>0.022315</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.015604</td>\n",
              "      <td>0.022202</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.015434</td>\n",
              "      <td>0.022083</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.015285</td>\n",
              "      <td>0.021960</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.015147</td>\n",
              "      <td>0.021836</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.015015</td>\n",
              "      <td>0.021711</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.014888</td>\n",
              "      <td>0.021587</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.014764</td>\n",
              "      <td>0.021464</td>\n",
              "      <td>0.981354</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.014645</td>\n",
              "      <td>0.021344</td>\n",
              "      <td>0.981354</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.014529</td>\n",
              "      <td>0.021225</td>\n",
              "      <td>0.981354</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.014416</td>\n",
              "      <td>0.021108</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.014306</td>\n",
              "      <td>0.020993</td>\n",
              "      <td>0.980373</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.014199</td>\n",
              "      <td>0.020880</td>\n",
              "      <td>0.980373</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.014095</td>\n",
              "      <td>0.020768</td>\n",
              "      <td>0.980373</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.013993</td>\n",
              "      <td>0.020659</td>\n",
              "      <td>0.980373</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.013893</td>\n",
              "      <td>0.020551</td>\n",
              "      <td>0.980373</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.013796</td>\n",
              "      <td>0.020445</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.013702</td>\n",
              "      <td>0.020341</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.013609</td>\n",
              "      <td>0.020239</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.013519</td>\n",
              "      <td>0.020139</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.013432</td>\n",
              "      <td>0.020041</td>\n",
              "      <td>0.980864</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.013347</td>\n",
              "      <td>0.019946</td>\n",
              "      <td>0.980373</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.013264</td>\n",
              "      <td>0.019853</td>\n",
              "      <td>0.981354</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.013184</td>\n",
              "      <td>0.019763</td>\n",
              "      <td>0.981354</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.013106</td>\n",
              "      <td>0.019675</td>\n",
              "      <td>0.981354</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.013031</td>\n",
              "      <td>0.019590</td>\n",
              "      <td>0.981354</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.012957</td>\n",
              "      <td>0.019508</td>\n",
              "      <td>0.981354</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.012886</td>\n",
              "      <td>0.019428</td>\n",
              "      <td>0.981354</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.012816</td>\n",
              "      <td>0.019350</td>\n",
              "      <td>0.981354</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.012749</td>\n",
              "      <td>0.019274</td>\n",
              "      <td>0.981354</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.012683</td>\n",
              "      <td>0.019201</td>\n",
              "      <td>0.981354</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.012618</td>\n",
              "      <td>0.019130</td>\n",
              "      <td>0.981354</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.012556</td>\n",
              "      <td>0.019062</td>\n",
              "      <td>0.981354</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.012494</td>\n",
              "      <td>0.018995</td>\n",
              "      <td>0.981354</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.012434</td>\n",
              "      <td>0.018930</td>\n",
              "      <td>0.981354</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.012375</td>\n",
              "      <td>0.018868</td>\n",
              "      <td>0.981845</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(L(learn.recorder.values).itemgot(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "rEGoxuPCeOlf",
        "outputId": "b5092c5e-a45d-47ba-8d86-bcf2dea8cef7"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7faaa63fa750>]"
            ]
          },
          "metadata": {},
          "execution_count": 246
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.recorder.values[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqE74STpeiBT",
        "outputId": "55ba2498-83f5-4271-e27f-84ec605eeb27"
      },
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [0.012374524027109146,0.018867703154683113,0.981844961643219]"
            ]
          },
          "metadata": {},
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no need to stop at just two linear layers. We can add as many as we want, as long as we add a nonlinearity between each pair of linear layers. As you will learn, however, the deeper the model gets, the harder it is to optimize the parameters in practice. Later in this book you will learn about some simple but brilliantly effective techniques for training deeper models.\n",
        "\n",
        "\n",
        "We already know that a single nonlinearity with two linear layers is enough to approximate any function. So why would we use deeper models? The reason is performance. With a deeper model (that is, one with more layers) we do not need to use as many parameters; it turns out that we can use smaller matrices with more layers, and get better results than we would get with larger matrices, and few layers.\n",
        "\n",
        "That means that we can train the model more quickly, and it will take up less memory."
      ],
      "metadata": {
        "id": "EaqjFEcJfALD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Here is what happens when we train an 18-layer model using the same approach we saw in <>:\n",
        "\n",
        "dls"
      ],
      "metadata": {
        "id": "gYrPT_j_fYjh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}